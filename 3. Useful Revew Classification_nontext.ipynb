{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import warnings # supress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "source": [
    "## Split Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('filted_nv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  date                                              hours\n",
       "0  2011-03-17 03:41:10  {'Monday': '11:0-0:0', 'Tuesday': '11:0-0:0', ...\n",
       "1  2010-04-03 22:55:37  {'Monday': '11:0-2:0', 'Tuesday': '11:0-2:0', ...\n",
       "2  2010-04-03 23:13:29  {'Monday': '6:0-14:30', 'Tuesday': '6:0-14:30'...\n",
       "3  2019-03-23 01:12:17  {'Monday': '4:30-21:0', 'Tuesday': '4:30-21:0'...\n",
       "4  2017-11-05 21:45:35  {'Monday': '6:0-13:0', 'Tuesday': '6:0-13:0', ..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>hours</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-03-17 03:41:10</td>\n      <td>{'Monday': '11:0-0:0', 'Tuesday': '11:0-0:0', ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010-04-03 22:55:37</td>\n      <td>{'Monday': '11:0-2:0', 'Tuesday': '11:0-2:0', ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010-04-03 23:13:29</td>\n      <td>{'Monday': '6:0-14:30', 'Tuesday': '6:0-14:30'...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-03-23 01:12:17</td>\n      <td>{'Monday': '4:30-21:0', 'Tuesday': '4:30-21:0'...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-11-05 21:45:35</td>\n      <td>{'Monday': '6:0-13:0', 'Tuesday': '6:0-13:0', ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df[['date','hours']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      review_id\n",
       "year           \n",
       "2005        112\n",
       "2006       1045\n",
       "2007       3972\n",
       "2008       9350\n",
       "2009      15472\n",
       "2010      30319\n",
       "2011      49161\n",
       "2012      56268\n",
       "2013      74437\n",
       "2014     112741\n",
       "2015     153753\n",
       "2016     186731\n",
       "2017     215582\n",
       "2018     254313\n",
       "2019     246998"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n    </tr>\n    <tr>\n      <th>year</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2005</th>\n      <td>112</td>\n    </tr>\n    <tr>\n      <th>2006</th>\n      <td>1045</td>\n    </tr>\n    <tr>\n      <th>2007</th>\n      <td>3972</td>\n    </tr>\n    <tr>\n      <th>2008</th>\n      <td>9350</td>\n    </tr>\n    <tr>\n      <th>2009</th>\n      <td>15472</td>\n    </tr>\n    <tr>\n      <th>2010</th>\n      <td>30319</td>\n    </tr>\n    <tr>\n      <th>2011</th>\n      <td>49161</td>\n    </tr>\n    <tr>\n      <th>2012</th>\n      <td>56268</td>\n    </tr>\n    <tr>\n      <th>2013</th>\n      <td>74437</td>\n    </tr>\n    <tr>\n      <th>2014</th>\n      <td>112741</td>\n    </tr>\n    <tr>\n      <th>2015</th>\n      <td>153753</td>\n    </tr>\n    <tr>\n      <th>2016</th>\n      <td>186731</td>\n    </tr>\n    <tr>\n      <th>2017</th>\n      <td>215582</td>\n    </tr>\n    <tr>\n      <th>2018</th>\n      <td>254313</td>\n    </tr>\n    <tr>\n      <th>2019</th>\n      <td>246998</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df[['year','review_id']].groupby(by='year').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['year']==2018].to_csv('filted_nv_2018.csv')\n",
    "df[df['year']==2017].to_csv('filted_nv_2017.csv')\n",
    "df[df['year']==2019].to_csv('filted_nv_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          attributes  \\\n",
       "0  {'RestaurantsReservations': 'True', 'Alcohol':...   \n",
       "1  {'RestaurantsReservations': 'True', 'Restauran...   \n",
       "2  {'RestaurantsTakeOut': 'True', 'NoiseLevel': \"...   \n",
       "3  {'BikeParking': 'False', 'RestaurantsReservati...   \n",
       "4  {'GoodForKids': 'True', 'RestaurantsTakeOut': ...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Nightlife, Bars, Restaurants, Burgers, America...   \n",
       "1                                  Restaurants, Thai   \n",
       "2  Cafes, Restaurants, American (New), Breakfast ...   \n",
       "3  Diners, Restaurants, Burgers, American (Tradit...   \n",
       "4  American (New), Breakfast & Brunch, American (...   \n",
       "\n",
       "                                               hours        yelping_since  \\\n",
       "0  {'Monday': '11:0-0:0', 'Tuesday': '11:0-0:0', ...  2009-03-01 06:03:45   \n",
       "1  {'Monday': '11:0-2:0', 'Tuesday': '11:0-2:0', ...  2009-03-01 06:03:45   \n",
       "2  {'Monday': '6:0-14:30', 'Tuesday': '6:0-14:30'...  2009-03-01 06:03:45   \n",
       "3  {'Monday': '4:30-21:0', 'Tuesday': '4:30-21:0'...  2009-08-31 03:13:14   \n",
       "4  {'Monday': '6:0-13:0', 'Tuesday': '6:0-13:0', ...  2017-11-05 14:33:43   \n",
       "\n",
       "                 elite  \n",
       "0  2011,2012,2013,2014  \n",
       "1  2011,2012,2013,2014  \n",
       "2  2011,2012,2013,2014  \n",
       "3                  NaN  \n",
       "4                  NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>attributes</th>\n      <th>categories</th>\n      <th>hours</th>\n      <th>yelping_since</th>\n      <th>elite</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'RestaurantsReservations': 'True', 'Alcohol':...</td>\n      <td>Nightlife, Bars, Restaurants, Burgers, America...</td>\n      <td>{'Monday': '11:0-0:0', 'Tuesday': '11:0-0:0', ...</td>\n      <td>2009-03-01 06:03:45</td>\n      <td>2011,2012,2013,2014</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'RestaurantsReservations': 'True', 'Restauran...</td>\n      <td>Restaurants, Thai</td>\n      <td>{'Monday': '11:0-2:0', 'Tuesday': '11:0-2:0', ...</td>\n      <td>2009-03-01 06:03:45</td>\n      <td>2011,2012,2013,2014</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'RestaurantsTakeOut': 'True', 'NoiseLevel': \"...</td>\n      <td>Cafes, Restaurants, American (New), Breakfast ...</td>\n      <td>{'Monday': '6:0-14:30', 'Tuesday': '6:0-14:30'...</td>\n      <td>2009-03-01 06:03:45</td>\n      <td>2011,2012,2013,2014</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'BikeParking': 'False', 'RestaurantsReservati...</td>\n      <td>Diners, Restaurants, Burgers, American (Tradit...</td>\n      <td>{'Monday': '4:30-21:0', 'Tuesday': '4:30-21:0'...</td>\n      <td>2009-08-31 03:13:14</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'GoodForKids': 'True', 'RestaurantsTakeOut': ...</td>\n      <td>American (New), Breakfast &amp; Brunch, American (...</td>\n      <td>{'Monday': '6:0-13:0', 'Tuesday': '6:0-13:0', ...</td>\n      <td>2017-11-05 14:33:43</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df[['attributes','categories','hours','yelping_since','elite']].head()"
   ]
  },
  {
   "source": [
    "## Read Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('filted_nv_2018.csv')\n",
    "df_19 = pd.read_csv('filted_nv_2019.csv')"
   ]
  },
  {
   "source": [
    "## Data Preprocess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['label'] = np.where((df['useful_r']+df['funny_r']+df['cool_r']) > 2, 1, 0)\n",
    "df_19['label'] = np.where((df_19['useful_r']+df_19['funny_r']+df_19['cool_r']) > 2, 1, 0)\n",
    "\n",
    "df['yelping_since_month'] = (pd.to_datetime(df['date']).dt.year-pd.to_datetime(df['yelping_since']).dt.year)*12+ (pd.to_datetime(df['date']).dt.month-pd.to_datetime(df['yelping_since']).dt.month)\n",
    "df_19['yelping_since_month'] = (pd.to_datetime(df_19['date']).dt.year-pd.to_datetime(df_19['yelping_since']).dt.year)*12+ (pd.to_datetime(df_19['date']).dt.month-pd.to_datetime(df_19['yelping_since']).dt.month)\n",
    "\n",
    "df['elite_u'] = df['elite'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "df_19['elite_u'] = df_19['elite'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "\n",
    "df['elite_count'] = df['elite'].apply(lambda x: len(x.split(',')) if pd.notnull(x) else 0)\n",
    "df_19['elite_count'] = df_19['elite'].apply(lambda x: len(x.split(',')) if pd.notnull(x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 254313 entries, 0 to 254312\nData columns (total 52 columns):\n #   Column               Non-Null Count   Dtype  \n---  ------               --------------   -----  \n 0   Unnamed: 0           254313 non-null  int64  \n 1   Unnamed: 0.1         254313 non-null  int64  \n 2   Unnamed: 0.1.1       254313 non-null  int64  \n 3   Unnamed: 0_x         254313 non-null  int64  \n 4   review_id            254313 non-null  object \n 5   user_id              254313 non-null  object \n 6   business_id          254313 non-null  object \n 7   stars_r              254313 non-null  int64  \n 8   useful_r             254313 non-null  int64  \n 9   funny_r              254313 non-null  int64  \n 10  cool_r               254313 non-null  float64\n 11  text                 254313 non-null  object \n 12  date                 254313 non-null  object \n 13  Unnamed: 0_y         254313 non-null  float64\n 14  name_b               254313 non-null  object \n 15  address              253875 non-null  object \n 16  city                 254313 non-null  object \n 17  state                254313 non-null  object \n 18  postal_code          254309 non-null  float64\n 19  latitude             254313 non-null  float64\n 20  longitude            254313 non-null  float64\n 21  stars_b              254313 non-null  float64\n 22  review_count_b       254313 non-null  float64\n 23  is_open              254313 non-null  float64\n 24  attributes           254263 non-null  object \n 25  categories           254313 non-null  object \n 26  hours                251081 non-null  object \n 27  funny_u              254313 non-null  int64  \n 28  review_count_u       254313 non-null  int64  \n 29  compliment_hot       254313 non-null  int64  \n 30  compliment_funny     254313 non-null  int64  \n 31  compliment_plain     254313 non-null  int64  \n 32  fans                 254313 non-null  int64  \n 33  compliment_photos    254313 non-null  int64  \n 34  compliment_profile   254313 non-null  int64  \n 35  useful_u             254313 non-null  int64  \n 36  yelping_since        254313 non-null  object \n 37  name_u               254311 non-null  object \n 38  average_stars        254313 non-null  float64\n 39  cool_u               254313 non-null  int64  \n 40  elite                43271 non-null   object \n 41  compliment_cute      254313 non-null  int64  \n 42  friends              254313 non-null  object \n 43  compliment_cool      254313 non-null  int64  \n 44  compliment_list      254313 non-null  int64  \n 45  compliment_writer    254313 non-null  int64  \n 46  compliment_more      254313 non-null  int64  \n 47  compliment_note      254313 non-null  int64  \n 48  year                 254313 non-null  int64  \n 49  label                254313 non-null  int64  \n 50  yelping_since_month  254313 non-null  int64  \n 51  elite_u              254313 non-null  int64  \ndtypes: float64(9), int64(27), object(16)\nmemory usage: 100.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_feature = ['stars_r', 'latitude',\n",
    "       'longitude',\n",
    "       'stars_b', 'review_count_b','funny_u',\n",
    "       'review_count_u', 'compliment_hot', 'compliment_funny',\n",
    "       'compliment_plain','fans','compliment_photos', 'compliment_profile',\n",
    "       'useful_u', 'average_stars', 'cool_u',\n",
    "       'compliment_cute', 'compliment_cool',\n",
    "       'compliment_list', 'compliment_writer', 'compliment_more',\n",
    "       'compliment_note','yelping_since_month','elite_u', 'elite_count']\n",
    "text_feature = ['text','city','attributes','categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df\n",
    "test_set = df_19\n",
    "del df\n",
    "del df_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_set['label']\n",
    "y_test = test_set['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "  scaler = preprocessing.StandardScaler().fit(train_set[continuous_feature])\n",
    "  X_train_pre = scaler.transform(train_set[continuous_feature])\n",
    "  X_test_pre = scaler.transform(test_set[continuous_feature])"
   ]
  },
  {
   "source": [
    "## Define Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_true, y_pred, probs):\n",
    "    print('Confusion Matrix: '+'\\n',metrics.confusion_matrix(y_true, y_pred))\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_true, y_pred))\n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "    roc_auc = metrics.roc_auc_score(y_true, probs[:,1])\n",
    "    print('AUC: ', roc_auc)"
   ]
  },
  {
   "source": [
    "# def fit_evaluate(model, X, y, x_test, y_true):\n",
    "def fit_evaluate(model, X, y, x_test, y_true, output='yes'):\n",
    "    model.fit(X,y)\n",
    "    y_pred = model.predict(x_test)\n",
    "    prob = model.predict_proba(x_test)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', metrics.confusion_matrix(y_true, y_pred))\n",
    "    acc = metrics.accuracy_score(y_true, y_pred)\n",
    "    precision = metrics.precision_score(y_true, y_pred)\n",
    "    recall = metrics.recall_score(y_true, y_pred)\n",
    "    f1 = metrics.f1_score(y_true, y_pred)\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_true, y_pred))\n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "    roc_auc = metrics.roc_auc_score(y_true, prob[:,1])\n",
    "    print(\"AUC:\", roc_auc)\n",
    "    if output == 'yes':\n",
    "        return y_pred, prob, acc, precision, recall, f1, roc_auc\n",
    "    else:\n",
    "        return None"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, parameter, X, y):\n",
    "    tuned = GridSearchCV(model, parameter, verbose=2)\n",
    "    tuned.fit(X,y)\n",
    "    print(\"Best score: {:.2%}\".format(tuned.best_score_))\n",
    "    print(\"Best Hyperparameters:{}\".format(tuned.best_params_))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "def standard_confusion_matrix(y_true, y_pred):\n",
    "    '''\n",
    "    Reformat confusion matrix output from sklearn for plotting profit curve.\n",
    "    '''\n",
    "    [[tn, fp], [fn, tp]] = metrics.confusion_matrix(y_true, y_pred)\n",
    "    return np.array([[tp, fp], [fn, tn]])\n",
    "\n",
    "def plot_confusion_matrix(y_real, y_pred, Model):\n",
    "    cm = standard_confusion_matrix(y_real, y_pred)\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, fmt='g', cmap=\"YlGnBu\",xticklabels=[1,0], yticklabels=[1,0])\n",
    "    ax.set_xlabel('True labels')\n",
    "    ax.set_ylabel('Predicted labels')\n",
    "    plt.title('{} Confusion Matrix'.format(Model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "def ROC_curve(probs, test, model_name):\n",
    "    auc = [0 for i in range(len(probs))]\n",
    "    fpr = [0 for i in range(len(probs))]\n",
    "    tpr = [0 for i in range(len(probs))]\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        # calculate scores\n",
    "        auc[i] = metrics.roc_auc_score(test, probs[i][:, 1])\n",
    "        # summarize scores\n",
    "        print('Model %s: ROC AUC=%.3f' % (model_name[i], auc[i]))\n",
    "        # calculate roc curves\n",
    "        fpr[i], tpr[i], _ = metrics.roc_curve(test, probs[i][:, 1])\n",
    "        # plot the roc curve for the model\n",
    "        plt.plot(fpr[i], tpr[i], label='Model %s' % (model_name[i]))\n",
    "    # axis labels\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    plt.title('ROC Curve')\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "# Continuous Features - Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## NB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_1 = MultinomialNB()\n",
    "nb_1.fit(train_set[continuous_feature],train_set['label'])\n",
    "y_1 = nb_1.predict(test_set[continuous_feature])\n",
    "y_1_prob = nb_1.predict_proba(test_set[continuous_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix: \n",
      " [[200066   8949]\n",
      " [ 22734  15249]]\n",
      "Accuracy:  0.871727706297217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93    209015\n",
      "           1       0.63      0.40      0.49     37983\n",
      "\n",
      "    accuracy                           0.87    246998\n",
      "   macro avg       0.76      0.68      0.71    246998\n",
      "weighted avg       0.86      0.87      0.86    246998\n",
      "\n",
      "AUC:  0.6885209831485246\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_test,y_1,y_1_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best score: 85.84%\n",
      "Best Hyperparameters:{'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters tuning\n",
    "\n",
    "tuned_parameters= {\n",
    "    'alpha': np.linspace(0.1, 0.5, 5),\n",
    "}\n",
    "\n",
    "nb_tuned = GridSearchCV(MultinomialNB(), tuned_parameters, verbose=1)\n",
    "nb_tuned.fit(train_set[continuous_feature],train_set['label'])\n",
    "\n",
    "print(\"Best score: {:.2%}\".format(nb_tuned.best_score_))\n",
    "print(\"Best Hyperparameters:{}\".format(nb_tuned.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix: \n",
      " [[200066   8949]\n",
      " [ 22734  15249]]\n",
      "Accuracy:  0.871727706297217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93    209015\n",
      "           1       0.63      0.40      0.49     37983\n",
      "\n",
      "    accuracy                           0.87    246998\n",
      "   macro avg       0.76      0.68      0.71    246998\n",
      "weighted avg       0.86      0.87      0.86    246998\n",
      "\n",
      "AUC: 0.6885209888797128\n"
     ]
    }
   ],
   "source": [
    "nb_new = MultinomialNB(alpha=0.1)\n",
    "# y_pred, prob, acc, precision, recall, f1, roc_auc\n",
    "mnb_pred, mnb_prob, mnb_acc, mnb_precision, mnb_recall, mnb_f1, mnb_auc = fit_evaluate(nb_new,train_set[continuous_feature],train_set['label'], test_set[continuous_feature], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix: \n",
      " [[208268    747]\n",
      " [ 31189   6794]]\n",
      "Accuracy:  0.8707034065053159\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93    209015\n",
      "           1       0.90      0.18      0.30     37983\n",
      "\n",
      "    accuracy                           0.87    246998\n",
      "   macro avg       0.89      0.59      0.61    246998\n",
      "weighted avg       0.87      0.87      0.83    246998\n",
      "\n",
      "AUC:  0.7708256691679266\n"
     ]
    }
   ],
   "source": [
    "nb_2 = GaussianNB()\n",
    "nb_2.fit(X_train_pre,y_train)\n",
    "y_2 = nb_2.predict(X_test_pre)\n",
    "y_2_prob = nb_2.predict_proba(X_test_pre)\n",
    "evaluation(y_test,y_2,y_2_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ................................var_smoothing=1e-06; total time=   0.2s\n",
      "[CV] END ................................var_smoothing=1e-06; total time=   0.1s\n",
      "[CV] END ................................var_smoothing=1e-06; total time=   0.1s\n",
      "[CV] END ................................var_smoothing=1e-06; total time=   0.1s\n",
      "[CV] END ................................var_smoothing=1e-06; total time=   0.1s\n",
      "[CV] END ................................var_smoothing=1e-07; total time=   0.1s\n",
      "[CV] END ................................var_smoothing=1e-07; total time=   0.1s\n",
      "[CV] END ................................var_smoothing=1e-07; total time=   0.1s\n",
      "[CV] END ................................var_smoothing=1e-07; total time=   0.1s\n",
      "[CV] END ................................var_smoothing=1e-07; total time=   0.1s\n",
      "[CV] END ................................var_smoothing=1e-08; total time=   0.1s\n",
      "[CV] END ................................var_smoothing=1e-08; total time=   0.1s\n",
      "[CV] END ................................var_smoothing=1e-08; total time=   0.1s\n",
      "[CV] END ................................var_smoothing=1e-08; total time=   0.1s\n",
      "[CV] END ................................var_smoothing=1e-08; total time=   0.1s\n",
      "Best score: 87.64%\n",
      "Best Hyperparameters:{'var_smoothing': 1e-07}\n"
     ]
    }
   ],
   "source": [
    "nb_2_parameter = {\n",
    "    'var_smoothing': [1e-6, 1e-7, 1e-8]\n",
    "}\n",
    "cross_val(nb_2, nb_2_parameter, X_train_pre, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix: \n",
      " [[208268    747]\n",
      " [ 31189   6794]]\n",
      "Accuracy:  0.8707034065053159\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93    209015\n",
      "           1       0.90      0.18      0.30     37983\n",
      "\n",
      "    accuracy                           0.87    246998\n",
      "   macro avg       0.89      0.59      0.61    246998\n",
      "weighted avg       0.87      0.87      0.83    246998\n",
      "\n",
      "AUC: 0.7708254283320572\n"
     ]
    }
   ],
   "source": [
    "nb_gaussian = GaussianNB(var_smoothing=1e-06)\n",
    "# y_pred, prob, acc, precision, recall, f1, roc_auc\n",
    "gnb_pred, gnb_prob, gnb_acc, gnb_precision, gnb_recall, gnb_f1, gnb_auc = fit_evaluate(nb_gaussian,X_train_pre,y_train,X_test_pre,y_test)"
   ]
  },
  {
   "source": [
    "## Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix: \n",
      " [[206594   2421]\n",
      " [ 27775  10208]]\n",
      "Accuracy:  0.8777479979594977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93    209015\n",
      "           1       0.81      0.27      0.40     37983\n",
      "\n",
      "    accuracy                           0.88    246998\n",
      "   macro avg       0.84      0.63      0.67    246998\n",
      "weighted avg       0.87      0.88      0.85    246998\n",
      "\n",
      "AUC: 0.7714010207066266\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "fit_evaluate(lr,X_train_pre,y_train,X_test_pre,y_test,output='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV] END ................................................C=1; total time=   1.3s\n",
      "[CV] END ................................................C=1; total time=   1.5s\n",
      "[CV] END ................................................C=1; total time=   1.3s\n",
      "[CV] END ................................................C=1; total time=   1.3s\n",
      "[CV] END ................................................C=1; total time=   1.2s\n",
      "[CV] END ................................................C=5; total time=   1.3s\n",
      "[CV] END ................................................C=5; total time=   1.3s\n",
      "[CV] END ................................................C=5; total time=   1.4s\n",
      "[CV] END ................................................C=5; total time=   1.3s\n",
      "[CV] END ................................................C=5; total time=   1.3s\n",
      "[CV] END ...............................................C=10; total time=   1.3s\n",
      "[CV] END ...............................................C=10; total time=   1.3s\n",
      "[CV] END ...............................................C=10; total time=   1.3s\n",
      "[CV] END ...............................................C=10; total time=   1.2s\n",
      "[CV] END ...............................................C=10; total time=   1.3s\n",
      "[CV] END ...............................................C=50; total time=   1.3s\n",
      "[CV] END ...............................................C=50; total time=   1.3s\n",
      "[CV] END ...............................................C=50; total time=   1.3s\n",
      "[CV] END ...............................................C=50; total time=   1.3s\n",
      "[CV] END ...............................................C=50; total time=   1.2s\n",
      "[CV] END ..............................................C=100; total time=   1.5s\n",
      "[CV] END ..............................................C=100; total time=   1.4s\n",
      "[CV] END ..............................................C=100; total time=   1.3s\n",
      "[CV] END ..............................................C=100; total time=   1.4s\n",
      "[CV] END ..............................................C=100; total time=   1.3s\n",
      "[CV] END ..............................................C=200; total time=   1.3s\n",
      "[CV] END ..............................................C=200; total time=   1.2s\n",
      "[CV] END ..............................................C=200; total time=   1.3s\n",
      "[CV] END ..............................................C=200; total time=   1.5s\n",
      "[CV] END ..............................................C=200; total time=   1.2s\n",
      "[CV] END ..............................................C=300; total time=   1.2s\n",
      "[CV] END ..............................................C=300; total time=   1.5s\n",
      "[CV] END ..............................................C=300; total time=   1.6s\n",
      "[CV] END ..............................................C=300; total time=   1.3s\n",
      "[CV] END ..............................................C=300; total time=   1.4s\n",
      "Best score: 88.16%\n",
      "Best Hyperparameters:{'C': 5}\n"
     ]
    }
   ],
   "source": [
    "lr_parameter = {\n",
    "    'C': [1, 5, 10, 50, 100, 200, 300]\n",
    "}\n",
    "cross_val(lr, lr_parameter, X_train_pre, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix: \n",
      " [[206621   2394]\n",
      " [ 27809  10174]]\n",
      "Accuracy:  0.8777196576490498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93    209015\n",
      "           1       0.81      0.27      0.40     37983\n",
      "\n",
      "    accuracy                           0.88    246998\n",
      "   macro avg       0.85      0.63      0.67    246998\n",
      "weighted avg       0.87      0.88      0.85    246998\n",
      "\n",
      "AUC: 0.7712056589823959\n"
     ]
    }
   ],
   "source": [
    "lr_new = LogisticRegression(C = 5)\n",
    "lr_pred, lr_prob, lr_acc, lr_precision, lr_recall, lr_f1, lr_auc = fit_evaluate(lr_new,X_train_pre,y_train,X_test_pre,y_test)"
   ]
  },
  {
   "source": [
    "## SVM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Too long to run.. > <\n",
    "from sklearn.svm import SVR, SVC\n",
    "svm = SVC(random_state=0, kernel = 'linear')\n",
    "fit_evaluate(svm,X_train_pre,y_train,X_test_pre,y_test,output='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_parameters = {\n",
    "    'C': [0.1, 1, 50, 100],\n",
    "    'kernel':['rbf','linear','sigmoid']}\n",
    "# cross_val(svm, svm_parameters, X_train_pre, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## KNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix: \n",
      " [[204039   4976]\n",
      " [ 26349  11634]]\n",
      "Accuracy:  0.873177110745836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93    209015\n",
      "           1       0.70      0.31      0.43     37983\n",
      "\n",
      "    accuracy                           0.87    246998\n",
      "   macro avg       0.79      0.64      0.68    246998\n",
      "weighted avg       0.86      0.87      0.85    246998\n",
      "\n",
      "AUC: 0.7154233444685851\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_pred, knn_prob, knn_acc, knn_precision, knn_recall, knn_f1, knn_auc = fit_evaluate(knn,X_train_pre,y_train,X_test_pre,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix: \n",
      " [[205029   3986]\n",
      " [ 23419  14564]]\n",
      "Accuracy:  0.8890476845966364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94    209015\n",
      "           1       0.79      0.38      0.52     37983\n",
      "\n",
      "    accuracy                           0.89    246998\n",
      "   macro avg       0.84      0.68      0.73    246998\n",
      "weighted avg       0.88      0.89      0.87    246998\n",
      "\n",
      "AUC: 0.8762346028406066\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "fit_evaluate(rf,X_train_pre,y_train,X_test_pre,y_test,output='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=50; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=50; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=50; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=50; total time=   4.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=50; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=100; total time=   7.6s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=100; total time=   7.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=100; total time=   7.6s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=100; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=100; total time=   7.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=   7.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=   7.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=   7.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=   7.6s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=   7.8s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=10; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=10; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=10; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=10; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=10; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=50; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=50; total time=   5.8s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=50; total time=   5.2s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=50; total time=   5.2s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=50; total time=   5.8s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100; total time=  10.5s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100; total time=  10.9s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100; total time=  10.6s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100; total time=  10.7s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100; total time=  10.7s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=10; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=10; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=10; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=10; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=10; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50; total time=   6.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100; total time=  10.5s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100; total time=  11.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100; total time=   9.9s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100; total time=  10.8s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100; total time=  11.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, n_estimators=10; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, n_estimators=10; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, n_estimators=10; total time=   3.2s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, n_estimators=10; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, n_estimators=10; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, n_estimators=50; total time=   8.3s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, n_estimators=50; total time=   7.9s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, n_estimators=50; total time=   8.7s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, n_estimators=50; total time=   8.9s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, n_estimators=50; total time=   8.6s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, n_estimators=100; total time=  17.2s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, n_estimators=100; total time=  16.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, n_estimators=100; total time=  17.9s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, n_estimators=100; total time=  18.3s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, n_estimators=100; total time=  17.7s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, n_estimators=10; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, n_estimators=10; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, n_estimators=10; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, n_estimators=10; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, n_estimators=10; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50; total time=   7.9s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50; total time=   8.9s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50; total time=   8.7s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50; total time=   8.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50; total time=   8.3s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100; total time=  17.1s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100; total time=  15.6s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100; total time=  16.9s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100; total time=  16.6s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100; total time=  16.5s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=50; total time=   3.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=50; total time=   3.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=50; total time=   3.7s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=50; total time=   3.7s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=50; total time=   3.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=100; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=100; total time=   7.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=100; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=100; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=100; total time=   7.7s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=10; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50; total time=   3.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50; total time=   4.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=   7.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=10; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=10; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=10; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=10; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=10; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=50; total time=   5.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=50; total time=   4.2s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=50; total time=   5.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=50; total time=   5.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=50; total time=   5.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100; total time=  10.0s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=10; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=10; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=10; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=10; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=10; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50; total time=   5.3s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50; total time=   5.3s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50; total time=   5.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50; total time=   5.3s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50; total time=   6.2s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100; total time=  11.4s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100; total time=  12.8s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100; total time=  11.0s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, n_estimators=10; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, n_estimators=10; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, n_estimators=10; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, n_estimators=10; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, n_estimators=10; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, n_estimators=50; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, n_estimators=50; total time=   7.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, n_estimators=50; total time=   8.7s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, n_estimators=50; total time=   8.1s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, n_estimators=50; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, n_estimators=100; total time=  17.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, n_estimators=100; total time=  16.9s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, n_estimators=100; total time=  16.9s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, n_estimators=100; total time=  16.4s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, n_estimators=100; total time=  16.7s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=10; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=10; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=10; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=10; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=10; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50; total time=   9.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50; total time=   8.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50; total time=   8.9s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50; total time=   8.7s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100; total time=  16.3s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100; total time=  15.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100; total time=  17.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100; total time=  17.4s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100; total time=  16.8s\n",
      "Best score: 88.45%\n",
      "Best Hyperparameters:{'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "rf_parameters= { \n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_features': ['auto', 'log2'],\n",
    "    'max_depth' : [3, 5, 10],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "cross_val(rf, rf_parameters, X_train_pre, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix: \n",
      " [[206551   2464]\n",
      " [ 26219  11764]]\n",
      "Accuracy:  0.8838735536320133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94    209015\n",
      "           1       0.83      0.31      0.45     37983\n",
      "\n",
      "    accuracy                           0.88    246998\n",
      "   macro avg       0.86      0.65      0.69    246998\n",
      "weighted avg       0.88      0.88      0.86    246998\n",
      "\n",
      "AUC: 0.8439144052970504\n"
     ]
    }
   ],
   "source": [
    "rf_new = RandomForestClassifier(random_state=0, n_estimators = 50, max_features = 'auto', max_depth = 3,  criterion = 'entropy')\n",
    "rf_pred, rf_prob, rf_acc, rf_precision, rf_recall, rf_f1, rf_auc = fit_evaluate(rf_new,X_train_pre,y_train,X_test_pre,y_test)"
   ]
  },
  {
   "source": [
    "## XGBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix: \n",
      " [[205267   3748]\n",
      " [ 22688  15295]]\n",
      "Accuracy:  0.8929707932857756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94    209015\n",
      "           1       0.80      0.40      0.54     37983\n",
      "\n",
      "    accuracy                           0.89    246998\n",
      "   macro avg       0.85      0.69      0.74    246998\n",
      "weighted avg       0.89      0.89      0.88    246998\n",
      "\n",
      "AUC: 0.8974304253719017\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(eval_metric='auc')\n",
    "fit_evaluate(xgb_model,X_train_pre,y_train,X_test_pre,y_test,output='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "13    0.378060\n6     0.113369\n3     0.073504\n21    0.060331\n0     0.056327\n4     0.056061\n11    0.042228\n9     0.040592\n2     0.022708\n1     0.021692\n8     0.019044\n17    0.013435\n20    0.013139\n5     0.012716\n12    0.012165\n16    0.011772\n10    0.011595\n14    0.011508\n18    0.010090\n19    0.009996\n7     0.009672\n15    0.000000\ndtype: float32\n"
     ]
    }
   ],
   "source": [
    "FI = pd.Series(xgb_model.feature_importances_)\n",
    "FI = FI.sort_values(ascending = False)\n",
    "print(FI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Thresh=0.378, n=1, Accuracy: 88.52%, AUC: 83.932%\n",
      "Thresh=0.113, n=2, Accuracy: 88.51%, AUC: 83.926%\n",
      "Thresh=0.074, n=3, Accuracy: 88.45%, AUC: 84.215%\n",
      "Thresh=0.060, n=4, Accuracy: 88.53%, AUC: 84.198%\n",
      "Thresh=0.056, n=5, Accuracy: 88.50%, AUC: 85.327%\n",
      "Thresh=0.056, n=6, Accuracy: 88.85%, AUC: 87.792%\n",
      "Thresh=0.042, n=7, Accuracy: 89.00%, AUC: 88.934%\n",
      "Thresh=0.041, n=8, Accuracy: 89.02%, AUC: 88.901%\n",
      "Thresh=0.023, n=9, Accuracy: 89.07%, AUC: 89.347%\n",
      "Thresh=0.022, n=10, Accuracy: 89.10%, AUC: 89.515%\n",
      "Thresh=0.019, n=11, Accuracy: 89.08%, AUC: 89.534%\n",
      "Thresh=0.013, n=12, Accuracy: 89.11%, AUC: 89.503%\n",
      "Thresh=0.013, n=13, Accuracy: 89.23%, AUC: 89.619%\n",
      "Thresh=0.013, n=14, Accuracy: 89.26%, AUC: 89.649%\n",
      "Thresh=0.012, n=15, Accuracy: 89.34%, AUC: 89.768%\n",
      "Thresh=0.012, n=16, Accuracy: 89.29%, AUC: 89.728%\n",
      "Thresh=0.012, n=17, Accuracy: 89.30%, AUC: 89.791%\n",
      "Thresh=0.012, n=18, Accuracy: 89.33%, AUC: 89.740%\n",
      "Thresh=0.010, n=19, Accuracy: 89.24%, AUC: 89.722%\n",
      "Thresh=0.010, n=20, Accuracy: 89.28%, AUC: 89.757%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from numpy import sort\n",
    "\n",
    "# Fit model using each importance as a threshold\n",
    "thresholds = sort(xgb_model.feature_importances_)\n",
    "\n",
    "for i in np.arange(len(thresholds)-1, 1, -1):\n",
    "    thresh = thresholds[i]\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(xgb_model, threshold=thresh, prefit=True)\n",
    "    select_x_train = selection.transform(X_train_pre)\n",
    "    # train model\n",
    "    selection_model = XGBClassifier(eval_metric='logloss')\n",
    "    selection_model.fit(select_x_train, y_train)\n",
    "    # eval model\n",
    "    select_x_val = selection.transform(X_test_pre)\n",
    "    predictions = selection_model.predict(select_x_val)\n",
    "    probs = selection_model.predict_proba(select_x_val)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, probs[:,1])\n",
    "    accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%, AUC: %.3f%%\" % (thresh, select_x_train.shape[1], accuracy*100.0, roc_auc*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['cool_u',\n",
       " 'compliment_funny',\n",
       " 'funny_u',\n",
       " 'elite_u',\n",
       " 'stars_r',\n",
       " 'review_count_u',\n",
       " 'useful_u',\n",
       " 'compliment_photos',\n",
       " 'review_count_b',\n",
       " 'stars_b',\n",
       " 'fans',\n",
       " 'compliment_writer',\n",
       " 'yelping_since_month',\n",
       " 'compliment_hot',\n",
       " 'average_stars',\n",
       " 'compliment_list',\n",
       " 'compliment_profile']"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "FI = pd.Series(xgb_model.feature_importances_, index = list(train_set[continuous_feature].columns)) \n",
    "FI = FI.sort_values(ascending = False).head(17)\n",
    "top_features = list(FI.index)\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ate=0.1, max_depth=10, n_estimators=50; total time=   5.6s\n",
      "[16:48:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.1, max_depth=10, n_estimators=50; total time=   5.0s\n",
      "[16:48:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.1, max_depth=10, n_estimators=50; total time=   5.3s\n",
      "[16:48:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.1, max_depth=10, n_estimators=50; total time=   5.6s\n",
      "[16:48:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.1, max_depth=10, n_estimators=150; total time=  15.0s\n",
      "[16:48:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.1, max_depth=10, n_estimators=150; total time=  15.2s\n",
      "[16:49:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.1, max_depth=10, n_estimators=150; total time=  14.2s\n",
      "[16:49:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.1, max_depth=10, n_estimators=150; total time=  15.3s\n",
      "[16:49:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.1, max_depth=10, n_estimators=150; total time=  14.7s\n",
      "[16:49:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=3, n_estimators=10; total time=   0.5s\n",
      "[16:49:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=3, n_estimators=10; total time=   0.4s\n",
      "[16:49:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=3, n_estimators=10; total time=   0.4s\n",
      "[16:50:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=3, n_estimators=10; total time=   0.5s\n",
      "[16:50:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=3, n_estimators=10; total time=   0.5s\n",
      "[16:50:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=3, n_estimators=50; total time=   1.8s\n",
      "[16:50:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=3, n_estimators=50; total time=   1.5s\n",
      "[16:50:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=3, n_estimators=50; total time=   1.7s\n",
      "[16:50:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=3, n_estimators=50; total time=   1.7s\n",
      "[16:50:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=3, n_estimators=50; total time=   1.7s\n",
      "[16:50:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=3, n_estimators=150; total time=   4.6s\n",
      "[16:50:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=3, n_estimators=150; total time=   4.3s\n",
      "[16:50:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=3, n_estimators=150; total time=   4.3s\n",
      "[16:50:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=3, n_estimators=150; total time=   4.3s\n",
      "[16:50:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=3, n_estimators=150; total time=   4.0s\n",
      "[16:50:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=6, n_estimators=10; total time=   0.7s\n",
      "[16:50:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=6, n_estimators=10; total time=   0.7s\n",
      "[16:50:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=6, n_estimators=10; total time=   0.8s\n",
      "[16:50:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=6, n_estimators=10; total time=   0.6s\n",
      "[16:50:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=6, n_estimators=10; total time=   0.7s\n",
      "[16:50:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   2.9s\n",
      "[16:50:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   2.7s\n",
      "[16:50:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   2.6s\n",
      "[16:50:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   2.7s\n",
      "[16:50:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   2.6s\n",
      "[16:50:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=6, n_estimators=150; total time=   8.9s\n",
      "[16:50:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=6, n_estimators=150; total time=   8.3s\n",
      "[16:51:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=6, n_estimators=150; total time=   9.0s\n",
      "[16:51:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=6, n_estimators=150; total time=   7.8s\n",
      "[16:51:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=6, n_estimators=150; total time=   7.3s\n",
      "[16:51:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=10, n_estimators=10; total time=   1.2s\n",
      "[16:51:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=10, n_estimators=10; total time=   1.2s\n",
      "[16:51:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=10, n_estimators=10; total time=   1.1s\n",
      "[16:51:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=10, n_estimators=10; total time=   1.3s\n",
      "[16:51:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=10, n_estimators=10; total time=   1.4s\n",
      "[16:51:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=10, n_estimators=50; total time=   5.1s\n",
      "[16:51:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=10, n_estimators=50; total time=   5.5s\n",
      "[16:51:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=10, n_estimators=50; total time=   5.8s\n",
      "[16:51:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=10, n_estimators=50; total time=   4.9s\n",
      "[16:51:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=10, n_estimators=50; total time=   5.6s\n",
      "[16:52:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=10, n_estimators=150; total time=  13.3s\n",
      "[16:52:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=10, n_estimators=150; total time=  13.9s\n",
      "[16:52:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=10, n_estimators=150; total time=  14.6s\n",
      "[16:52:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=10, n_estimators=150; total time=  13.0s\n",
      "[16:52:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END gamma=5, learning_rate=0.3, max_depth=10, n_estimators=150; total time=  12.9s\n",
      "[16:53:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best score: 88.75%\n",
      "Best Hyperparameters:{'gamma': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "xgb_parameters = {\n",
    "        'n_estimators': [10, 50, 150],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "         'gamma': [0.5, 1, 5],\n",
    "        'max_depth': [3, 6, 10]\n",
    "        }\n",
    "cross_val(xgb_model, xgb_parameters, X_train_pre, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[17:01:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Confusion Matrix: \n",
      " [[205171   3844]\n",
      " [ 22638  15345]]\n",
      "Accuracy:  0.8927845569599754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94    209015\n",
      "           1       0.80      0.40      0.54     37983\n",
      "\n",
      "    accuracy                           0.89    246998\n",
      "   macro avg       0.85      0.69      0.74    246998\n",
      "weighted avg       0.89      0.89      0.88    246998\n",
      "\n",
      "AUC: 0.8969000539625389\n"
     ]
    }
   ],
   "source": [
    "xgb_new = XGBClassifier(random_state=0, n_estimators = 150, learning_rate = 0.1, max_depth = 10,  gamma = 1)\n",
    "xgb_pred, xgb_prob, xgb_acc, xgb_precision, xgb_recall, xgb_f1, xgb_auc = fit_evaluate(xgb_new,X_train_pre,y_train,X_test_pre,y_test)"
   ]
  },
  {
   "source": [
    "## LightGBM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix: \n",
      " [[206050   2965]\n",
      " [ 23329  14654]]\n",
      "Accuracy:  0.8935456967262893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94    209015\n",
      "           1       0.83      0.39      0.53     37983\n",
      "\n",
      "    accuracy                           0.89    246998\n",
      "   macro avg       0.87      0.69      0.73    246998\n",
      "weighted avg       0.89      0.89      0.88    246998\n",
      "\n",
      "AUC: 0.8980664414129536\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(random_state=0)\n",
    "fit_evaluate(lgbm,X_train_pre,y_train,X_test_pre,y_test,output='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "al time=   1.2s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, num_leaves=80; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, num_leaves=80; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, num_leaves=15; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, num_leaves=15; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, num_leaves=15; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, num_leaves=15; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, num_leaves=15; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, num_leaves=31; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, num_leaves=31; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, num_leaves=31; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, num_leaves=31; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, num_leaves=31; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, num_leaves=80; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, num_leaves=80; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, num_leaves=80; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, num_leaves=80; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, num_leaves=80; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=300, num_leaves=15; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=300, num_leaves=15; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=300, num_leaves=15; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=300, num_leaves=15; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=300, num_leaves=15; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=300, num_leaves=31; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=300, num_leaves=31; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=300, num_leaves=31; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=300, num_leaves=31; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=300, num_leaves=31; total time=   3.1s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=300, num_leaves=80; total time=   5.4s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=300, num_leaves=80; total time=   5.4s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=300, num_leaves=80; total time=   5.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=300, num_leaves=80; total time=   5.8s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=300, num_leaves=80; total time=   6.0s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=50, num_leaves=31; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=50, num_leaves=31; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=50, num_leaves=31; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=50, num_leaves=31; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=50, num_leaves=31; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=50, num_leaves=80; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=50, num_leaves=80; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=50, num_leaves=80; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=50, num_leaves=80; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=50, num_leaves=80; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=100, num_leaves=15; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=100, num_leaves=15; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=100, num_leaves=15; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=100, num_leaves=15; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=100, num_leaves=15; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=100, num_leaves=31; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=100, num_leaves=31; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=100, num_leaves=31; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=100, num_leaves=31; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=100, num_leaves=31; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=100, num_leaves=80; total time=   2.3s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=100, num_leaves=80; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=100, num_leaves=80; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=100, num_leaves=80; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=100, num_leaves=80; total time=   2.3s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=300, num_leaves=15; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=300, num_leaves=15; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=300, num_leaves=15; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=300, num_leaves=15; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=300, num_leaves=15; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=300, num_leaves=31; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=300, num_leaves=31; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=300, num_leaves=31; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=300, num_leaves=31; total time=   3.5s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=300, num_leaves=31; total time=   3.8s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=300, num_leaves=80; total time=   6.7s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=300, num_leaves=80; total time=   6.2s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=300, num_leaves=80; total time=   5.7s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=300, num_leaves=80; total time=   6.4s\n",
      "[CV] END learning_rate=0.1, max_depth=30, n_estimators=300, num_leaves=80; total time=   6.5s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=50, num_leaves=15; total time=   0.7s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=50, num_leaves=15; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=50, num_leaves=15; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=50, num_leaves=15; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=50, num_leaves=31; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=50, num_leaves=31; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=50, num_leaves=31; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=50, num_leaves=31; total time=   1.0s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=50, num_leaves=31; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=50, num_leaves=80; total time=   1.6s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=50, num_leaves=80; total time=   1.3s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=50, num_leaves=80; total time=   1.3s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=50, num_leaves=80; total time=   1.3s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=50, num_leaves=80; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=100, num_leaves=15; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=100, num_leaves=15; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=100, num_leaves=15; total time=   1.0s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=100, num_leaves=15; total time=   1.0s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=100, num_leaves=15; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=100, num_leaves=31; total time=   1.1s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=100, num_leaves=31; total time=   1.1s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=100, num_leaves=31; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=100, num_leaves=31; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=100, num_leaves=31; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=100, num_leaves=80; total time=   2.1s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=100, num_leaves=80; total time=   2.1s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=100, num_leaves=80; total time=   2.2s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=100, num_leaves=80; total time=   2.3s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=100, num_leaves=80; total time=   2.2s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=300, num_leaves=15; total time=   1.8s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=300, num_leaves=15; total time=   1.9s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=300, num_leaves=15; total time=   1.9s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=300, num_leaves=15; total time=   1.9s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=300, num_leaves=15; total time=   1.9s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=300, num_leaves=31; total time=   2.8s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=300, num_leaves=31; total time=   2.8s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=300, num_leaves=31; total time=   2.8s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=300, num_leaves=31; total time=   2.8s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=300, num_leaves=31; total time=   2.9s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=300, num_leaves=80; total time=   5.7s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=300, num_leaves=80; total time=   5.6s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=300, num_leaves=80; total time=   5.8s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=300, num_leaves=80; total time=   6.0s\n",
      "[CV] END learning_rate=0.3, max_depth=-1, n_estimators=300, num_leaves=80; total time=   5.7s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=50, num_leaves=31; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=50, num_leaves=31; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=50, num_leaves=31; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=50, num_leaves=31; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=50, num_leaves=31; total time=   0.7s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=50, num_leaves=80; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=50, num_leaves=80; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=50, num_leaves=80; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=50, num_leaves=80; total time=   1.3s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=50, num_leaves=80; total time=   1.6s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, num_leaves=15; total time=   1.1s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, num_leaves=15; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, num_leaves=15; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, num_leaves=15; total time=   1.1s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, num_leaves=15; total time=   1.1s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, num_leaves=31; total time=   1.4s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, num_leaves=31; total time=   1.4s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, num_leaves=31; total time=   1.5s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, num_leaves=31; total time=   1.1s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, num_leaves=31; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, num_leaves=80; total time=   2.6s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, num_leaves=80; total time=   2.4s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, num_leaves=80; total time=   2.3s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, num_leaves=80; total time=   2.4s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, num_leaves=80; total time=   2.1s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=300, num_leaves=15; total time=   1.9s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=300, num_leaves=15; total time=   1.8s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=300, num_leaves=15; total time=   1.7s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=300, num_leaves=15; total time=   1.8s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=300, num_leaves=15; total time=   1.8s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=300, num_leaves=31; total time=   3.0s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=300, num_leaves=31; total time=   3.0s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=300, num_leaves=31; total time=   3.1s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=300, num_leaves=31; total time=   3.2s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=300, num_leaves=31; total time=   2.9s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=300, num_leaves=80; total time=   5.6s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=300, num_leaves=80; total time=   5.3s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=300, num_leaves=80; total time=   5.2s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=300, num_leaves=80; total time=   5.7s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=300, num_leaves=80; total time=   6.2s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=50, num_leaves=15; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=50, num_leaves=31; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=50, num_leaves=31; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=50, num_leaves=31; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=50, num_leaves=31; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=50, num_leaves=31; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=50, num_leaves=80; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=50, num_leaves=80; total time=   1.3s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=50, num_leaves=80; total time=   1.4s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=50, num_leaves=80; total time=   1.5s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=50, num_leaves=80; total time=   1.4s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=100, num_leaves=15; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=100, num_leaves=15; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=100, num_leaves=15; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=100, num_leaves=15; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=100, num_leaves=15; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=100, num_leaves=31; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=100, num_leaves=31; total time=   1.1s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=100, num_leaves=31; total time=   1.1s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=100, num_leaves=31; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=100, num_leaves=31; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=100, num_leaves=80; total time=   2.1s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=100, num_leaves=80; total time=   2.1s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=100, num_leaves=80; total time=   2.2s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=100, num_leaves=80; total time=   2.1s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=100, num_leaves=80; total time=   2.3s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=300, num_leaves=15; total time=   2.0s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=300, num_leaves=15; total time=   1.9s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=300, num_leaves=15; total time=   1.8s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=300, num_leaves=15; total time=   1.8s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=300, num_leaves=15; total time=   1.8s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=300, num_leaves=31; total time=   2.8s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=300, num_leaves=31; total time=   2.7s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=300, num_leaves=31; total time=   2.8s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=300, num_leaves=31; total time=   2.8s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=300, num_leaves=31; total time=   2.8s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=300, num_leaves=80; total time=   5.7s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=300, num_leaves=80; total time=   5.7s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=300, num_leaves=80; total time=   5.9s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=300, num_leaves=80; total time=   5.8s\n",
      "[CV] END learning_rate=0.3, max_depth=30, n_estimators=300, num_leaves=80; total time=   5.6s\n",
      "Best score: 88.80%\n",
      "Best Hyperparameters:{'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 50, 'num_leaves': 15}\n"
     ]
    }
   ],
   "source": [
    "lgbm_parameters = {\n",
    "        'n_estimators': [50, 100, 300],\n",
    "        'num_leaves': [15, 31, 80],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'max_depth': [-1, 10, 30]\n",
    "        }\n",
    "cross_val(lgbm, lgbm_parameters, X_train_pre, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix: \n",
      " [[206407   2608]\n",
      " [ 24196  13787]]\n",
      "Accuracy:  0.891480902679374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94    209015\n",
      "           1       0.84      0.36      0.51     37983\n",
      "\n",
      "    accuracy                           0.89    246998\n",
      "   macro avg       0.87      0.68      0.72    246998\n",
      "weighted avg       0.89      0.89      0.87    246998\n",
      "\n",
      "AUC: 0.8931410477834936\n"
     ]
    }
   ],
   "source": [
    "lgbm_new = LGBMClassifier(random_state=0, n_estimators = 50, num_leaves = 15, max_depth = -1,  learning_rate = 0.1)\n",
    "lgbm_pred, lgbm_prob, lgbm_acc, lgbm_precision, lgbm_recall, lgbm_f1, lgbm_auc = fit_evaluate(lgbm_new,X_train_pre,y_train,X_test_pre,y_test)"
   ]
  },
  {
   "source": [
    "## CatBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "g: 12.2s\n",
      "622:\tlearn: 0.2240745\ttotal: 20.1s\tremaining: 12.2s\n",
      "623:\tlearn: 0.2240496\ttotal: 20.2s\tremaining: 12.2s\n",
      "624:\tlearn: 0.2240319\ttotal: 20.2s\tremaining: 12.1s\n",
      "625:\tlearn: 0.2240127\ttotal: 20.2s\tremaining: 12.1s\n",
      "626:\tlearn: 0.2239913\ttotal: 20.3s\tremaining: 12.1s\n",
      "627:\tlearn: 0.2239621\ttotal: 20.3s\tremaining: 12s\n",
      "628:\tlearn: 0.2239319\ttotal: 20.3s\tremaining: 12s\n",
      "629:\tlearn: 0.2239085\ttotal: 20.3s\tremaining: 11.9s\n",
      "630:\tlearn: 0.2238752\ttotal: 20.4s\tremaining: 11.9s\n",
      "631:\tlearn: 0.2238603\ttotal: 20.4s\tremaining: 11.9s\n",
      "632:\tlearn: 0.2238603\ttotal: 20.4s\tremaining: 11.8s\n",
      "633:\tlearn: 0.2238473\ttotal: 20.4s\tremaining: 11.8s\n",
      "634:\tlearn: 0.2238160\ttotal: 20.5s\tremaining: 11.8s\n",
      "635:\tlearn: 0.2237917\ttotal: 20.5s\tremaining: 11.7s\n",
      "636:\tlearn: 0.2237538\ttotal: 20.5s\tremaining: 11.7s\n",
      "637:\tlearn: 0.2237370\ttotal: 20.6s\tremaining: 11.7s\n",
      "638:\tlearn: 0.2237055\ttotal: 20.6s\tremaining: 11.6s\n",
      "639:\tlearn: 0.2236964\ttotal: 20.6s\tremaining: 11.6s\n",
      "640:\tlearn: 0.2236748\ttotal: 20.6s\tremaining: 11.6s\n",
      "641:\tlearn: 0.2236444\ttotal: 20.7s\tremaining: 11.5s\n",
      "642:\tlearn: 0.2235999\ttotal: 20.7s\tremaining: 11.5s\n",
      "643:\tlearn: 0.2235680\ttotal: 20.7s\tremaining: 11.5s\n",
      "644:\tlearn: 0.2235432\ttotal: 20.7s\tremaining: 11.4s\n",
      "645:\tlearn: 0.2234996\ttotal: 20.8s\tremaining: 11.4s\n",
      "646:\tlearn: 0.2234723\ttotal: 20.8s\tremaining: 11.3s\n",
      "647:\tlearn: 0.2234419\ttotal: 20.8s\tremaining: 11.3s\n",
      "648:\tlearn: 0.2234202\ttotal: 20.9s\tremaining: 11.3s\n",
      "649:\tlearn: 0.2234006\ttotal: 20.9s\tremaining: 11.2s\n",
      "650:\tlearn: 0.2233697\ttotal: 20.9s\tremaining: 11.2s\n",
      "651:\tlearn: 0.2233481\ttotal: 20.9s\tremaining: 11.2s\n",
      "652:\tlearn: 0.2233114\ttotal: 21s\tremaining: 11.2s\n",
      "653:\tlearn: 0.2232896\ttotal: 21s\tremaining: 11.1s\n",
      "654:\tlearn: 0.2232607\ttotal: 21.1s\tremaining: 11.1s\n",
      "655:\tlearn: 0.2232362\ttotal: 21.1s\tremaining: 11.1s\n",
      "656:\tlearn: 0.2231972\ttotal: 21.2s\tremaining: 11.1s\n",
      "657:\tlearn: 0.2231576\ttotal: 21.3s\tremaining: 11s\n",
      "658:\tlearn: 0.2231314\ttotal: 21.3s\tremaining: 11s\n",
      "659:\tlearn: 0.2230954\ttotal: 21.3s\tremaining: 11s\n",
      "660:\tlearn: 0.2230649\ttotal: 21.4s\tremaining: 11s\n",
      "661:\tlearn: 0.2230452\ttotal: 21.4s\tremaining: 10.9s\n",
      "662:\tlearn: 0.2230207\ttotal: 21.4s\tremaining: 10.9s\n",
      "663:\tlearn: 0.2229930\ttotal: 21.5s\tremaining: 10.9s\n",
      "664:\tlearn: 0.2229572\ttotal: 21.5s\tremaining: 10.8s\n",
      "665:\tlearn: 0.2229350\ttotal: 21.5s\tremaining: 10.8s\n",
      "666:\tlearn: 0.2228954\ttotal: 21.6s\tremaining: 10.8s\n",
      "667:\tlearn: 0.2228651\ttotal: 21.6s\tremaining: 10.7s\n",
      "668:\tlearn: 0.2228454\ttotal: 21.6s\tremaining: 10.7s\n",
      "669:\tlearn: 0.2228122\ttotal: 21.6s\tremaining: 10.7s\n",
      "670:\tlearn: 0.2227900\ttotal: 21.7s\tremaining: 10.6s\n",
      "671:\tlearn: 0.2227630\ttotal: 21.7s\tremaining: 10.6s\n",
      "672:\tlearn: 0.2227399\ttotal: 21.7s\tremaining: 10.6s\n",
      "673:\tlearn: 0.2227001\ttotal: 21.7s\tremaining: 10.5s\n",
      "674:\tlearn: 0.2226829\ttotal: 21.8s\tremaining: 10.5s\n",
      "675:\tlearn: 0.2226600\ttotal: 21.8s\tremaining: 10.4s\n",
      "676:\tlearn: 0.2226414\ttotal: 21.8s\tremaining: 10.4s\n",
      "677:\tlearn: 0.2226160\ttotal: 21.9s\tremaining: 10.4s\n",
      "678:\tlearn: 0.2225838\ttotal: 21.9s\tremaining: 10.3s\n",
      "679:\tlearn: 0.2225671\ttotal: 21.9s\tremaining: 10.3s\n",
      "680:\tlearn: 0.2225426\ttotal: 22s\tremaining: 10.3s\n",
      "681:\tlearn: 0.2225097\ttotal: 22s\tremaining: 10.3s\n",
      "682:\tlearn: 0.2224791\ttotal: 22s\tremaining: 10.2s\n",
      "683:\tlearn: 0.2224661\ttotal: 22s\tremaining: 10.2s\n",
      "684:\tlearn: 0.2224396\ttotal: 22.1s\tremaining: 10.2s\n",
      "685:\tlearn: 0.2224154\ttotal: 22.1s\tremaining: 10.1s\n",
      "686:\tlearn: 0.2223972\ttotal: 22.1s\tremaining: 10.1s\n",
      "687:\tlearn: 0.2223796\ttotal: 22.2s\tremaining: 10.1s\n",
      "688:\tlearn: 0.2223647\ttotal: 22.2s\tremaining: 10s\n",
      "689:\tlearn: 0.2223292\ttotal: 22.2s\tremaining: 9.98s\n",
      "690:\tlearn: 0.2223181\ttotal: 22.3s\tremaining: 9.95s\n",
      "691:\tlearn: 0.2223173\ttotal: 22.3s\tremaining: 9.91s\n",
      "692:\tlearn: 0.2222936\ttotal: 22.3s\tremaining: 9.88s\n",
      "693:\tlearn: 0.2222730\ttotal: 22.3s\tremaining: 9.85s\n",
      "694:\tlearn: 0.2222534\ttotal: 22.4s\tremaining: 9.81s\n",
      "695:\tlearn: 0.2222260\ttotal: 22.4s\tremaining: 9.78s\n",
      "696:\tlearn: 0.2222124\ttotal: 22.4s\tremaining: 9.75s\n",
      "697:\tlearn: 0.2221775\ttotal: 22.5s\tremaining: 9.71s\n",
      "698:\tlearn: 0.2221596\ttotal: 22.5s\tremaining: 9.68s\n",
      "699:\tlearn: 0.2221330\ttotal: 22.5s\tremaining: 9.64s\n",
      "700:\tlearn: 0.2221156\ttotal: 22.5s\tremaining: 9.61s\n",
      "701:\tlearn: 0.2220859\ttotal: 22.6s\tremaining: 9.57s\n",
      "702:\tlearn: 0.2220590\ttotal: 22.6s\tremaining: 9.54s\n",
      "703:\tlearn: 0.2220441\ttotal: 22.6s\tremaining: 9.51s\n",
      "704:\tlearn: 0.2220211\ttotal: 22.7s\tremaining: 9.48s\n",
      "705:\tlearn: 0.2220025\ttotal: 22.7s\tremaining: 9.44s\n",
      "706:\tlearn: 0.2219770\ttotal: 22.7s\tremaining: 9.41s\n",
      "707:\tlearn: 0.2219497\ttotal: 22.7s\tremaining: 9.37s\n",
      "708:\tlearn: 0.2219099\ttotal: 22.8s\tremaining: 9.34s\n",
      "709:\tlearn: 0.2218747\ttotal: 22.8s\tremaining: 9.31s\n",
      "710:\tlearn: 0.2218486\ttotal: 22.8s\tremaining: 9.28s\n",
      "711:\tlearn: 0.2218283\ttotal: 22.9s\tremaining: 9.25s\n",
      "712:\tlearn: 0.2218017\ttotal: 22.9s\tremaining: 9.22s\n",
      "713:\tlearn: 0.2217726\ttotal: 22.9s\tremaining: 9.19s\n",
      "714:\tlearn: 0.2217533\ttotal: 23s\tremaining: 9.16s\n",
      "715:\tlearn: 0.2217373\ttotal: 23s\tremaining: 9.13s\n",
      "716:\tlearn: 0.2217109\ttotal: 23s\tremaining: 9.09s\n",
      "717:\tlearn: 0.2216873\ttotal: 23.1s\tremaining: 9.06s\n",
      "718:\tlearn: 0.2216499\ttotal: 23.1s\tremaining: 9.03s\n",
      "719:\tlearn: 0.2216170\ttotal: 23.1s\tremaining: 8.99s\n",
      "720:\tlearn: 0.2215824\ttotal: 23.2s\tremaining: 8.96s\n",
      "721:\tlearn: 0.2215586\ttotal: 23.2s\tremaining: 8.93s\n",
      "722:\tlearn: 0.2215386\ttotal: 23.2s\tremaining: 8.89s\n",
      "723:\tlearn: 0.2215147\ttotal: 23.3s\tremaining: 8.86s\n",
      "724:\tlearn: 0.2214938\ttotal: 23.3s\tremaining: 8.84s\n",
      "725:\tlearn: 0.2214648\ttotal: 23.3s\tremaining: 8.8s\n",
      "726:\tlearn: 0.2214377\ttotal: 23.4s\tremaining: 8.77s\n",
      "727:\tlearn: 0.2214087\ttotal: 23.4s\tremaining: 8.74s\n",
      "728:\tlearn: 0.2213965\ttotal: 23.4s\tremaining: 8.7s\n",
      "729:\tlearn: 0.2213802\ttotal: 23.4s\tremaining: 8.67s\n",
      "730:\tlearn: 0.2213737\ttotal: 23.5s\tremaining: 8.63s\n",
      "731:\tlearn: 0.2213351\ttotal: 23.5s\tremaining: 8.6s\n",
      "732:\tlearn: 0.2213228\ttotal: 23.5s\tremaining: 8.57s\n",
      "733:\tlearn: 0.2213105\ttotal: 23.6s\tremaining: 8.54s\n",
      "734:\tlearn: 0.2212927\ttotal: 23.6s\tremaining: 8.51s\n",
      "735:\tlearn: 0.2212773\ttotal: 23.6s\tremaining: 8.48s\n",
      "736:\tlearn: 0.2212441\ttotal: 23.7s\tremaining: 8.45s\n",
      "737:\tlearn: 0.2212072\ttotal: 23.7s\tremaining: 8.43s\n",
      "738:\tlearn: 0.2211865\ttotal: 23.8s\tremaining: 8.4s\n",
      "739:\tlearn: 0.2211586\ttotal: 23.8s\tremaining: 8.37s\n",
      "740:\tlearn: 0.2211277\ttotal: 23.9s\tremaining: 8.34s\n",
      "741:\tlearn: 0.2210854\ttotal: 23.9s\tremaining: 8.31s\n",
      "742:\tlearn: 0.2210612\ttotal: 23.9s\tremaining: 8.28s\n",
      "743:\tlearn: 0.2210360\ttotal: 24s\tremaining: 8.25s\n",
      "744:\tlearn: 0.2210172\ttotal: 24s\tremaining: 8.22s\n",
      "745:\tlearn: 0.2209930\ttotal: 24.1s\tremaining: 8.19s\n",
      "746:\tlearn: 0.2209593\ttotal: 24.1s\tremaining: 8.16s\n",
      "747:\tlearn: 0.2209477\ttotal: 24.1s\tremaining: 8.13s\n",
      "748:\tlearn: 0.2209198\ttotal: 24.2s\tremaining: 8.1s\n",
      "749:\tlearn: 0.2208825\ttotal: 24.2s\tremaining: 8.07s\n",
      "750:\tlearn: 0.2208513\ttotal: 24.3s\tremaining: 8.04s\n",
      "751:\tlearn: 0.2208065\ttotal: 24.3s\tremaining: 8.02s\n",
      "752:\tlearn: 0.2207687\ttotal: 24.4s\tremaining: 7.99s\n",
      "753:\tlearn: 0.2207445\ttotal: 24.4s\tremaining: 7.96s\n",
      "754:\tlearn: 0.2207212\ttotal: 24.4s\tremaining: 7.93s\n",
      "755:\tlearn: 0.2206991\ttotal: 24.5s\tremaining: 7.9s\n",
      "756:\tlearn: 0.2206789\ttotal: 24.5s\tremaining: 7.87s\n",
      "757:\tlearn: 0.2206604\ttotal: 24.6s\tremaining: 7.84s\n",
      "758:\tlearn: 0.2206417\ttotal: 24.6s\tremaining: 7.81s\n",
      "759:\tlearn: 0.2206251\ttotal: 24.6s\tremaining: 7.78s\n",
      "760:\tlearn: 0.2206049\ttotal: 24.7s\tremaining: 7.75s\n",
      "761:\tlearn: 0.2205782\ttotal: 24.7s\tremaining: 7.72s\n",
      "762:\tlearn: 0.2205277\ttotal: 24.8s\tremaining: 7.69s\n",
      "763:\tlearn: 0.2204913\ttotal: 24.8s\tremaining: 7.66s\n",
      "764:\tlearn: 0.2204668\ttotal: 24.9s\tremaining: 7.63s\n",
      "765:\tlearn: 0.2204538\ttotal: 24.9s\tremaining: 7.6s\n",
      "766:\tlearn: 0.2204237\ttotal: 24.9s\tremaining: 7.57s\n",
      "767:\tlearn: 0.2203959\ttotal: 25s\tremaining: 7.54s\n",
      "768:\tlearn: 0.2203603\ttotal: 25s\tremaining: 7.51s\n",
      "769:\tlearn: 0.2203353\ttotal: 25.1s\tremaining: 7.48s\n",
      "770:\tlearn: 0.2203084\ttotal: 25.1s\tremaining: 7.45s\n",
      "771:\tlearn: 0.2202898\ttotal: 25.1s\tremaining: 7.42s\n",
      "772:\tlearn: 0.2202672\ttotal: 25.2s\tremaining: 7.4s\n",
      "773:\tlearn: 0.2202429\ttotal: 25.2s\tremaining: 7.37s\n",
      "774:\tlearn: 0.2202136\ttotal: 25.3s\tremaining: 7.34s\n",
      "775:\tlearn: 0.2201873\ttotal: 25.3s\tremaining: 7.31s\n",
      "776:\tlearn: 0.2201611\ttotal: 25.4s\tremaining: 7.28s\n",
      "777:\tlearn: 0.2200952\ttotal: 25.4s\tremaining: 7.25s\n",
      "778:\tlearn: 0.2200802\ttotal: 25.4s\tremaining: 7.22s\n",
      "779:\tlearn: 0.2200494\ttotal: 25.5s\tremaining: 7.19s\n",
      "780:\tlearn: 0.2200186\ttotal: 25.5s\tremaining: 7.16s\n",
      "781:\tlearn: 0.2199753\ttotal: 25.6s\tremaining: 7.13s\n",
      "782:\tlearn: 0.2199383\ttotal: 25.6s\tremaining: 7.09s\n",
      "783:\tlearn: 0.2199229\ttotal: 25.6s\tremaining: 7.06s\n",
      "784:\tlearn: 0.2198993\ttotal: 25.7s\tremaining: 7.03s\n",
      "785:\tlearn: 0.2198664\ttotal: 25.7s\tremaining: 7s\n",
      "786:\tlearn: 0.2198471\ttotal: 25.7s\tremaining: 6.97s\n",
      "787:\tlearn: 0.2198188\ttotal: 25.8s\tremaining: 6.94s\n",
      "788:\tlearn: 0.2197891\ttotal: 25.8s\tremaining: 6.91s\n",
      "789:\tlearn: 0.2197584\ttotal: 25.9s\tremaining: 6.88s\n",
      "790:\tlearn: 0.2197374\ttotal: 25.9s\tremaining: 6.85s\n",
      "791:\tlearn: 0.2197102\ttotal: 26s\tremaining: 6.82s\n",
      "792:\tlearn: 0.2196826\ttotal: 26s\tremaining: 6.79s\n",
      "793:\tlearn: 0.2196548\ttotal: 26s\tremaining: 6.76s\n",
      "794:\tlearn: 0.2196326\ttotal: 26.1s\tremaining: 6.73s\n",
      "795:\tlearn: 0.2196130\ttotal: 26.1s\tremaining: 6.7s\n",
      "796:\tlearn: 0.2195803\ttotal: 26.2s\tremaining: 6.67s\n",
      "797:\tlearn: 0.2195538\ttotal: 26.2s\tremaining: 6.63s\n",
      "798:\tlearn: 0.2195310\ttotal: 26.3s\tremaining: 6.61s\n",
      "799:\tlearn: 0.2194964\ttotal: 26.3s\tremaining: 6.57s\n",
      "800:\tlearn: 0.2194415\ttotal: 26.3s\tremaining: 6.54s\n",
      "801:\tlearn: 0.2194147\ttotal: 26.4s\tremaining: 6.51s\n",
      "802:\tlearn: 0.2193905\ttotal: 26.4s\tremaining: 6.48s\n",
      "803:\tlearn: 0.2193532\ttotal: 26.5s\tremaining: 6.45s\n",
      "804:\tlearn: 0.2193276\ttotal: 26.5s\tremaining: 6.42s\n",
      "805:\tlearn: 0.2193033\ttotal: 26.5s\tremaining: 6.39s\n",
      "806:\tlearn: 0.2192747\ttotal: 26.6s\tremaining: 6.36s\n",
      "807:\tlearn: 0.2192471\ttotal: 26.6s\tremaining: 6.33s\n",
      "808:\tlearn: 0.2192248\ttotal: 26.6s\tremaining: 6.29s\n",
      "809:\tlearn: 0.2192042\ttotal: 26.7s\tremaining: 6.26s\n",
      "810:\tlearn: 0.2191822\ttotal: 26.7s\tremaining: 6.23s\n",
      "811:\tlearn: 0.2191592\ttotal: 26.8s\tremaining: 6.2s\n",
      "812:\tlearn: 0.2191346\ttotal: 26.8s\tremaining: 6.17s\n",
      "813:\tlearn: 0.2191171\ttotal: 26.8s\tremaining: 6.13s\n",
      "814:\tlearn: 0.2190871\ttotal: 26.9s\tremaining: 6.1s\n",
      "815:\tlearn: 0.2190563\ttotal: 26.9s\tremaining: 6.07s\n",
      "816:\tlearn: 0.2190330\ttotal: 27s\tremaining: 6.04s\n",
      "817:\tlearn: 0.2190106\ttotal: 27s\tremaining: 6.01s\n",
      "818:\tlearn: 0.2189838\ttotal: 27s\tremaining: 5.98s\n",
      "819:\tlearn: 0.2189630\ttotal: 27.1s\tremaining: 5.94s\n",
      "820:\tlearn: 0.2189321\ttotal: 27.1s\tremaining: 5.91s\n",
      "821:\tlearn: 0.2189218\ttotal: 27.1s\tremaining: 5.88s\n",
      "822:\tlearn: 0.2188247\ttotal: 27.2s\tremaining: 5.84s\n",
      "823:\tlearn: 0.2187990\ttotal: 27.2s\tremaining: 5.81s\n",
      "824:\tlearn: 0.2187751\ttotal: 27.2s\tremaining: 5.78s\n",
      "825:\tlearn: 0.2187548\ttotal: 27.3s\tremaining: 5.74s\n",
      "826:\tlearn: 0.2187316\ttotal: 27.3s\tremaining: 5.71s\n",
      "827:\tlearn: 0.2187019\ttotal: 27.3s\tremaining: 5.68s\n",
      "828:\tlearn: 0.2186761\ttotal: 27.4s\tremaining: 5.64s\n",
      "829:\tlearn: 0.2186595\ttotal: 27.4s\tremaining: 5.61s\n",
      "830:\tlearn: 0.2186422\ttotal: 27.4s\tremaining: 5.58s\n",
      "831:\tlearn: 0.2186198\ttotal: 27.5s\tremaining: 5.54s\n",
      "832:\tlearn: 0.2185923\ttotal: 27.5s\tremaining: 5.51s\n",
      "833:\tlearn: 0.2185658\ttotal: 27.5s\tremaining: 5.47s\n",
      "834:\tlearn: 0.2185487\ttotal: 27.5s\tremaining: 5.44s\n",
      "835:\tlearn: 0.2185240\ttotal: 27.6s\tremaining: 5.41s\n",
      "836:\tlearn: 0.2184842\ttotal: 27.6s\tremaining: 5.38s\n",
      "837:\tlearn: 0.2184271\ttotal: 27.7s\tremaining: 5.35s\n",
      "838:\tlearn: 0.2183976\ttotal: 27.7s\tremaining: 5.32s\n",
      "839:\tlearn: 0.2183662\ttotal: 27.8s\tremaining: 5.29s\n",
      "840:\tlearn: 0.2183356\ttotal: 27.8s\tremaining: 5.26s\n",
      "841:\tlearn: 0.2183242\ttotal: 27.9s\tremaining: 5.23s\n",
      "842:\tlearn: 0.2182978\ttotal: 27.9s\tremaining: 5.2s\n",
      "843:\tlearn: 0.2182779\ttotal: 28s\tremaining: 5.17s\n",
      "844:\tlearn: 0.2182454\ttotal: 28s\tremaining: 5.14s\n",
      "845:\tlearn: 0.2182140\ttotal: 28.1s\tremaining: 5.11s\n",
      "846:\tlearn: 0.2181913\ttotal: 28.1s\tremaining: 5.08s\n",
      "847:\tlearn: 0.2181531\ttotal: 28.1s\tremaining: 5.04s\n",
      "848:\tlearn: 0.2181272\ttotal: 28.2s\tremaining: 5.01s\n",
      "849:\tlearn: 0.2181002\ttotal: 28.2s\tremaining: 4.98s\n",
      "850:\tlearn: 0.2180558\ttotal: 28.2s\tremaining: 4.94s\n",
      "851:\tlearn: 0.2180327\ttotal: 28.3s\tremaining: 4.91s\n",
      "852:\tlearn: 0.2179966\ttotal: 28.3s\tremaining: 4.88s\n",
      "853:\tlearn: 0.2179639\ttotal: 28.3s\tremaining: 4.84s\n",
      "854:\tlearn: 0.2179391\ttotal: 28.4s\tremaining: 4.81s\n",
      "855:\tlearn: 0.2179183\ttotal: 28.4s\tremaining: 4.77s\n",
      "856:\tlearn: 0.2179006\ttotal: 28.4s\tremaining: 4.74s\n",
      "857:\tlearn: 0.2178794\ttotal: 28.4s\tremaining: 4.7s\n",
      "858:\tlearn: 0.2178569\ttotal: 28.5s\tremaining: 4.67s\n",
      "859:\tlearn: 0.2178224\ttotal: 28.5s\tremaining: 4.64s\n",
      "860:\tlearn: 0.2177976\ttotal: 28.6s\tremaining: 4.61s\n",
      "861:\tlearn: 0.2177651\ttotal: 28.6s\tremaining: 4.58s\n",
      "862:\tlearn: 0.2177385\ttotal: 28.7s\tremaining: 4.55s\n",
      "863:\tlearn: 0.2177203\ttotal: 28.7s\tremaining: 4.52s\n",
      "864:\tlearn: 0.2176920\ttotal: 28.8s\tremaining: 4.49s\n",
      "865:\tlearn: 0.2176684\ttotal: 28.8s\tremaining: 4.46s\n",
      "866:\tlearn: 0.2176573\ttotal: 28.9s\tremaining: 4.43s\n",
      "867:\tlearn: 0.2176403\ttotal: 28.9s\tremaining: 4.4s\n",
      "868:\tlearn: 0.2176114\ttotal: 29s\tremaining: 4.37s\n",
      "869:\tlearn: 0.2175804\ttotal: 29s\tremaining: 4.33s\n",
      "870:\tlearn: 0.2175394\ttotal: 29s\tremaining: 4.3s\n",
      "871:\tlearn: 0.2175118\ttotal: 29.1s\tremaining: 4.26s\n",
      "872:\tlearn: 0.2174781\ttotal: 29.1s\tremaining: 4.23s\n",
      "873:\tlearn: 0.2174519\ttotal: 29.1s\tremaining: 4.2s\n",
      "874:\tlearn: 0.2174189\ttotal: 29.1s\tremaining: 4.16s\n",
      "875:\tlearn: 0.2173980\ttotal: 29.2s\tremaining: 4.13s\n",
      "876:\tlearn: 0.2173762\ttotal: 29.2s\tremaining: 4.09s\n",
      "877:\tlearn: 0.2173547\ttotal: 29.2s\tremaining: 4.06s\n",
      "878:\tlearn: 0.2173220\ttotal: 29.3s\tremaining: 4.03s\n",
      "879:\tlearn: 0.2172764\ttotal: 29.3s\tremaining: 3.99s\n",
      "880:\tlearn: 0.2172565\ttotal: 29.3s\tremaining: 3.96s\n",
      "881:\tlearn: 0.2172378\ttotal: 29.4s\tremaining: 3.93s\n",
      "882:\tlearn: 0.2172144\ttotal: 29.4s\tremaining: 3.9s\n",
      "883:\tlearn: 0.2171823\ttotal: 29.4s\tremaining: 3.86s\n",
      "884:\tlearn: 0.2171527\ttotal: 29.5s\tremaining: 3.83s\n",
      "885:\tlearn: 0.2171210\ttotal: 29.5s\tremaining: 3.79s\n",
      "886:\tlearn: 0.2171016\ttotal: 29.5s\tremaining: 3.76s\n",
      "887:\tlearn: 0.2170815\ttotal: 29.5s\tremaining: 3.73s\n",
      "888:\tlearn: 0.2170564\ttotal: 29.6s\tremaining: 3.69s\n",
      "889:\tlearn: 0.2170285\ttotal: 29.6s\tremaining: 3.66s\n",
      "890:\tlearn: 0.2170078\ttotal: 29.6s\tremaining: 3.63s\n",
      "891:\tlearn: 0.2169943\ttotal: 29.7s\tremaining: 3.59s\n",
      "892:\tlearn: 0.2169748\ttotal: 29.7s\tremaining: 3.56s\n",
      "893:\tlearn: 0.2169505\ttotal: 29.7s\tremaining: 3.52s\n",
      "894:\tlearn: 0.2169324\ttotal: 29.7s\tremaining: 3.49s\n",
      "895:\tlearn: 0.2168893\ttotal: 29.8s\tremaining: 3.46s\n",
      "896:\tlearn: 0.2168662\ttotal: 29.8s\tremaining: 3.42s\n",
      "897:\tlearn: 0.2168406\ttotal: 29.8s\tremaining: 3.39s\n",
      "898:\tlearn: 0.2168147\ttotal: 29.9s\tremaining: 3.35s\n",
      "899:\tlearn: 0.2167901\ttotal: 29.9s\tremaining: 3.32s\n",
      "900:\tlearn: 0.2167587\ttotal: 29.9s\tremaining: 3.29s\n",
      "901:\tlearn: 0.2167424\ttotal: 29.9s\tremaining: 3.25s\n",
      "902:\tlearn: 0.2167223\ttotal: 30s\tremaining: 3.22s\n",
      "903:\tlearn: 0.2167029\ttotal: 30s\tremaining: 3.19s\n",
      "904:\tlearn: 0.2166871\ttotal: 30s\tremaining: 3.15s\n",
      "905:\tlearn: 0.2166687\ttotal: 30.1s\tremaining: 3.12s\n",
      "906:\tlearn: 0.2166360\ttotal: 30.1s\tremaining: 3.08s\n",
      "907:\tlearn: 0.2166209\ttotal: 30.1s\tremaining: 3.05s\n",
      "908:\tlearn: 0.2166084\ttotal: 30.1s\tremaining: 3.02s\n",
      "909:\tlearn: 0.2165894\ttotal: 30.2s\tremaining: 2.98s\n",
      "910:\tlearn: 0.2165670\ttotal: 30.2s\tremaining: 2.95s\n",
      "911:\tlearn: 0.2165377\ttotal: 30.2s\tremaining: 2.92s\n",
      "912:\tlearn: 0.2165151\ttotal: 30.3s\tremaining: 2.88s\n",
      "913:\tlearn: 0.2164808\ttotal: 30.3s\tremaining: 2.85s\n",
      "914:\tlearn: 0.2164533\ttotal: 30.3s\tremaining: 2.82s\n",
      "915:\tlearn: 0.2164345\ttotal: 30.3s\tremaining: 2.78s\n",
      "916:\tlearn: 0.2164117\ttotal: 30.4s\tremaining: 2.75s\n",
      "917:\tlearn: 0.2163920\ttotal: 30.4s\tremaining: 2.71s\n",
      "918:\tlearn: 0.2163722\ttotal: 30.4s\tremaining: 2.68s\n",
      "919:\tlearn: 0.2163512\ttotal: 30.5s\tremaining: 2.65s\n",
      "920:\tlearn: 0.2163293\ttotal: 30.5s\tremaining: 2.62s\n",
      "921:\tlearn: 0.2163053\ttotal: 30.5s\tremaining: 2.58s\n",
      "922:\tlearn: 0.2162723\ttotal: 30.5s\tremaining: 2.55s\n",
      "923:\tlearn: 0.2162494\ttotal: 30.6s\tremaining: 2.51s\n",
      "924:\tlearn: 0.2162368\ttotal: 30.6s\tremaining: 2.48s\n",
      "925:\tlearn: 0.2162167\ttotal: 30.6s\tremaining: 2.45s\n",
      "926:\tlearn: 0.2161839\ttotal: 30.6s\tremaining: 2.41s\n",
      "927:\tlearn: 0.2161616\ttotal: 30.7s\tremaining: 2.38s\n",
      "928:\tlearn: 0.2161462\ttotal: 30.7s\tremaining: 2.35s\n",
      "929:\tlearn: 0.2161419\ttotal: 30.7s\tremaining: 2.31s\n",
      "930:\tlearn: 0.2161237\ttotal: 30.8s\tremaining: 2.28s\n",
      "931:\tlearn: 0.2161069\ttotal: 30.8s\tremaining: 2.25s\n",
      "932:\tlearn: 0.2160952\ttotal: 30.8s\tremaining: 2.21s\n",
      "933:\tlearn: 0.2160761\ttotal: 30.8s\tremaining: 2.18s\n",
      "934:\tlearn: 0.2160461\ttotal: 30.9s\tremaining: 2.15s\n",
      "935:\tlearn: 0.2160218\ttotal: 30.9s\tremaining: 2.11s\n",
      "936:\tlearn: 0.2159943\ttotal: 30.9s\tremaining: 2.08s\n",
      "937:\tlearn: 0.2159721\ttotal: 31s\tremaining: 2.05s\n",
      "938:\tlearn: 0.2159545\ttotal: 31s\tremaining: 2.01s\n",
      "939:\tlearn: 0.2159243\ttotal: 31s\tremaining: 1.98s\n",
      "940:\tlearn: 0.2158984\ttotal: 31.1s\tremaining: 1.95s\n",
      "941:\tlearn: 0.2158938\ttotal: 31.1s\tremaining: 1.91s\n",
      "942:\tlearn: 0.2158626\ttotal: 31.1s\tremaining: 1.88s\n",
      "943:\tlearn: 0.2158355\ttotal: 31.1s\tremaining: 1.85s\n",
      "944:\tlearn: 0.2158043\ttotal: 31.2s\tremaining: 1.81s\n",
      "945:\tlearn: 0.2157811\ttotal: 31.2s\tremaining: 1.78s\n",
      "946:\tlearn: 0.2157579\ttotal: 31.2s\tremaining: 1.75s\n",
      "947:\tlearn: 0.2157306\ttotal: 31.3s\tremaining: 1.72s\n",
      "948:\tlearn: 0.2157100\ttotal: 31.3s\tremaining: 1.68s\n",
      "949:\tlearn: 0.2156942\ttotal: 31.3s\tremaining: 1.65s\n",
      "950:\tlearn: 0.2156619\ttotal: 31.4s\tremaining: 1.62s\n",
      "951:\tlearn: 0.2156389\ttotal: 31.4s\tremaining: 1.58s\n",
      "952:\tlearn: 0.2156210\ttotal: 31.4s\tremaining: 1.55s\n",
      "953:\tlearn: 0.2156037\ttotal: 31.4s\tremaining: 1.52s\n",
      "954:\tlearn: 0.2155875\ttotal: 31.5s\tremaining: 1.48s\n",
      "955:\tlearn: 0.2155646\ttotal: 31.5s\tremaining: 1.45s\n",
      "956:\tlearn: 0.2155354\ttotal: 31.5s\tremaining: 1.42s\n",
      "957:\tlearn: 0.2155192\ttotal: 31.6s\tremaining: 1.38s\n",
      "958:\tlearn: 0.2154901\ttotal: 31.6s\tremaining: 1.35s\n",
      "959:\tlearn: 0.2154763\ttotal: 31.6s\tremaining: 1.32s\n",
      "960:\tlearn: 0.2154597\ttotal: 31.6s\tremaining: 1.28s\n",
      "961:\tlearn: 0.2154392\ttotal: 31.7s\tremaining: 1.25s\n",
      "962:\tlearn: 0.2154048\ttotal: 31.7s\tremaining: 1.22s\n",
      "963:\tlearn: 0.2153950\ttotal: 31.7s\tremaining: 1.18s\n",
      "964:\tlearn: 0.2153608\ttotal: 31.8s\tremaining: 1.15s\n",
      "965:\tlearn: 0.2153170\ttotal: 31.8s\tremaining: 1.12s\n",
      "966:\tlearn: 0.2152913\ttotal: 31.8s\tremaining: 1.08s\n",
      "967:\tlearn: 0.2152632\ttotal: 31.9s\tremaining: 1.05s\n",
      "968:\tlearn: 0.2152438\ttotal: 31.9s\tremaining: 1.02s\n",
      "969:\tlearn: 0.2152239\ttotal: 31.9s\tremaining: 987ms\n",
      "970:\tlearn: 0.2151910\ttotal: 31.9s\tremaining: 954ms\n",
      "971:\tlearn: 0.2151755\ttotal: 32s\tremaining: 921ms\n",
      "972:\tlearn: 0.2151529\ttotal: 32s\tremaining: 888ms\n",
      "973:\tlearn: 0.2151380\ttotal: 32s\tremaining: 855ms\n",
      "974:\tlearn: 0.2151230\ttotal: 32s\tremaining: 822ms\n",
      "975:\tlearn: 0.2151128\ttotal: 32.1s\tremaining: 789ms\n",
      "976:\tlearn: 0.2150952\ttotal: 32.1s\tremaining: 756ms\n",
      "977:\tlearn: 0.2150648\ttotal: 32.2s\tremaining: 724ms\n",
      "978:\tlearn: 0.2150401\ttotal: 32.2s\tremaining: 691ms\n",
      "979:\tlearn: 0.2150193\ttotal: 32.3s\tremaining: 658ms\n",
      "980:\tlearn: 0.2150082\ttotal: 32.3s\tremaining: 625ms\n",
      "981:\tlearn: 0.2149823\ttotal: 32.3s\tremaining: 592ms\n",
      "982:\tlearn: 0.2149688\ttotal: 32.3s\tremaining: 559ms\n",
      "983:\tlearn: 0.2149450\ttotal: 32.4s\tremaining: 526ms\n",
      "984:\tlearn: 0.2149206\ttotal: 32.4s\tremaining: 493ms\n",
      "985:\tlearn: 0.2149026\ttotal: 32.4s\tremaining: 460ms\n",
      "986:\tlearn: 0.2148810\ttotal: 32.4s\tremaining: 427ms\n",
      "987:\tlearn: 0.2148562\ttotal: 32.5s\tremaining: 395ms\n",
      "988:\tlearn: 0.2148448\ttotal: 32.5s\tremaining: 362ms\n",
      "989:\tlearn: 0.2148281\ttotal: 32.5s\tremaining: 329ms\n",
      "990:\tlearn: 0.2148056\ttotal: 32.6s\tremaining: 296ms\n",
      "991:\tlearn: 0.2147805\ttotal: 32.6s\tremaining: 263ms\n",
      "992:\tlearn: 0.2147561\ttotal: 32.6s\tremaining: 230ms\n",
      "993:\tlearn: 0.2147382\ttotal: 32.6s\tremaining: 197ms\n",
      "994:\tlearn: 0.2147221\ttotal: 32.7s\tremaining: 164ms\n",
      "995:\tlearn: 0.2147029\ttotal: 32.7s\tremaining: 131ms\n",
      "996:\tlearn: 0.2146759\ttotal: 32.7s\tremaining: 98.5ms\n",
      "997:\tlearn: 0.2146511\ttotal: 32.8s\tremaining: 65.7ms\n",
      "998:\tlearn: 0.2146375\ttotal: 32.8s\tremaining: 32.8ms\n",
      "999:\tlearn: 0.2146249\ttotal: 32.8s\tremaining: 0us\n",
      "Confusion Matrix: \n",
      " [[205398   3617]\n",
      " [ 22944  15039]]\n",
      "Accuracy:  0.8924647163134924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94    209015\n",
      "           1       0.81      0.40      0.53     37983\n",
      "\n",
      "    accuracy                           0.89    246998\n",
      "   macro avg       0.85      0.69      0.74    246998\n",
      "weighted avg       0.89      0.89      0.88    246998\n",
      "\n",
      "AUC: 0.8975389480678062\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier()\n",
    "fit_evaluate(cat,X_train_pre,y_train,X_test_pre,y_test,output='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4.5s\tremaining: 9.09s\n",
      "615:\tlearn: 0.2608861\ttotal: 14.5s\tremaining: 9.07s\n",
      "616:\tlearn: 0.2608600\ttotal: 14.6s\tremaining: 9.05s\n",
      "617:\tlearn: 0.2608339\ttotal: 14.6s\tremaining: 9.03s\n",
      "618:\tlearn: 0.2608110\ttotal: 14.6s\tremaining: 9.01s\n",
      "619:\tlearn: 0.2607938\ttotal: 14.7s\tremaining: 8.98s\n",
      "620:\tlearn: 0.2607667\ttotal: 14.7s\tremaining: 8.96s\n",
      "621:\tlearn: 0.2607513\ttotal: 14.7s\tremaining: 8.93s\n",
      "622:\tlearn: 0.2607373\ttotal: 14.7s\tremaining: 8.9s\n",
      "623:\tlearn: 0.2607167\ttotal: 14.7s\tremaining: 8.88s\n",
      "624:\tlearn: 0.2606130\ttotal: 14.8s\tremaining: 8.85s\n",
      "625:\tlearn: 0.2605958\ttotal: 14.8s\tremaining: 8.83s\n",
      "626:\tlearn: 0.2605748\ttotal: 14.8s\tremaining: 8.8s\n",
      "627:\tlearn: 0.2605550\ttotal: 14.8s\tremaining: 8.78s\n",
      "628:\tlearn: 0.2605402\ttotal: 14.8s\tremaining: 8.76s\n",
      "629:\tlearn: 0.2605204\ttotal: 14.9s\tremaining: 8.73s\n",
      "630:\tlearn: 0.2604692\ttotal: 14.9s\tremaining: 8.71s\n",
      "631:\tlearn: 0.2603825\ttotal: 14.9s\tremaining: 8.69s\n",
      "632:\tlearn: 0.2603653\ttotal: 14.9s\tremaining: 8.66s\n",
      "633:\tlearn: 0.2603449\ttotal: 15s\tremaining: 8.63s\n",
      "634:\tlearn: 0.2603294\ttotal: 15s\tremaining: 8.61s\n",
      "635:\tlearn: 0.2603152\ttotal: 15s\tremaining: 8.58s\n",
      "636:\tlearn: 0.2602977\ttotal: 15s\tremaining: 8.56s\n",
      "637:\tlearn: 0.2602663\ttotal: 15.1s\tremaining: 8.54s\n",
      "638:\tlearn: 0.2602372\ttotal: 15.1s\tremaining: 8.52s\n",
      "639:\tlearn: 0.2602184\ttotal: 15.1s\tremaining: 8.5s\n",
      "640:\tlearn: 0.2601475\ttotal: 15.1s\tremaining: 8.47s\n",
      "641:\tlearn: 0.2600932\ttotal: 15.1s\tremaining: 8.45s\n",
      "642:\tlearn: 0.2600636\ttotal: 15.2s\tremaining: 8.42s\n",
      "643:\tlearn: 0.2600445\ttotal: 15.2s\tremaining: 8.39s\n",
      "644:\tlearn: 0.2600271\ttotal: 15.2s\tremaining: 8.37s\n",
      "645:\tlearn: 0.2600047\ttotal: 15.2s\tremaining: 8.34s\n",
      "646:\tlearn: 0.2599838\ttotal: 15.3s\tremaining: 8.32s\n",
      "647:\tlearn: 0.2599657\ttotal: 15.3s\tremaining: 8.3s\n",
      "648:\tlearn: 0.2598855\ttotal: 15.3s\tremaining: 8.27s\n",
      "649:\tlearn: 0.2598622\ttotal: 15.3s\tremaining: 8.25s\n",
      "650:\tlearn: 0.2598418\ttotal: 15.3s\tremaining: 8.23s\n",
      "651:\tlearn: 0.2598176\ttotal: 15.4s\tremaining: 8.2s\n",
      "652:\tlearn: 0.2597970\ttotal: 15.4s\tremaining: 8.18s\n",
      "653:\tlearn: 0.2597797\ttotal: 15.4s\tremaining: 8.15s\n",
      "654:\tlearn: 0.2597554\ttotal: 15.4s\tremaining: 8.13s\n",
      "655:\tlearn: 0.2597360\ttotal: 15.4s\tremaining: 8.1s\n",
      "656:\tlearn: 0.2597241\ttotal: 15.5s\tremaining: 8.08s\n",
      "657:\tlearn: 0.2597061\ttotal: 15.5s\tremaining: 8.06s\n",
      "658:\tlearn: 0.2596893\ttotal: 15.5s\tremaining: 8.04s\n",
      "659:\tlearn: 0.2596613\ttotal: 15.6s\tremaining: 8.01s\n",
      "660:\tlearn: 0.2596324\ttotal: 15.6s\tremaining: 7.99s\n",
      "661:\tlearn: 0.2596086\ttotal: 15.6s\tremaining: 7.96s\n",
      "662:\tlearn: 0.2595839\ttotal: 15.6s\tremaining: 7.94s\n",
      "663:\tlearn: 0.2594965\ttotal: 15.6s\tremaining: 7.92s\n",
      "664:\tlearn: 0.2594794\ttotal: 15.7s\tremaining: 7.89s\n",
      "665:\tlearn: 0.2594650\ttotal: 15.7s\tremaining: 7.87s\n",
      "666:\tlearn: 0.2594339\ttotal: 15.7s\tremaining: 7.84s\n",
      "667:\tlearn: 0.2594113\ttotal: 15.7s\tremaining: 7.82s\n",
      "668:\tlearn: 0.2593947\ttotal: 15.8s\tremaining: 7.8s\n",
      "669:\tlearn: 0.2593764\ttotal: 15.8s\tremaining: 7.78s\n",
      "670:\tlearn: 0.2593428\ttotal: 15.8s\tremaining: 7.75s\n",
      "671:\tlearn: 0.2593252\ttotal: 15.8s\tremaining: 7.73s\n",
      "672:\tlearn: 0.2592897\ttotal: 15.9s\tremaining: 7.7s\n",
      "673:\tlearn: 0.2592757\ttotal: 15.9s\tremaining: 7.68s\n",
      "674:\tlearn: 0.2592588\ttotal: 15.9s\tremaining: 7.65s\n",
      "675:\tlearn: 0.2592225\ttotal: 15.9s\tremaining: 7.63s\n",
      "676:\tlearn: 0.2592064\ttotal: 15.9s\tremaining: 7.61s\n",
      "677:\tlearn: 0.2591897\ttotal: 16s\tremaining: 7.58s\n",
      "678:\tlearn: 0.2591664\ttotal: 16s\tremaining: 7.56s\n",
      "679:\tlearn: 0.2591460\ttotal: 16s\tremaining: 7.54s\n",
      "680:\tlearn: 0.2591176\ttotal: 16s\tremaining: 7.52s\n",
      "681:\tlearn: 0.2590947\ttotal: 16.1s\tremaining: 7.49s\n",
      "682:\tlearn: 0.2590828\ttotal: 16.1s\tremaining: 7.47s\n",
      "683:\tlearn: 0.2590264\ttotal: 16.1s\tremaining: 7.45s\n",
      "684:\tlearn: 0.2590063\ttotal: 16.1s\tremaining: 7.43s\n",
      "685:\tlearn: 0.2589819\ttotal: 16.2s\tremaining: 7.4s\n",
      "686:\tlearn: 0.2589667\ttotal: 16.2s\tremaining: 7.38s\n",
      "687:\tlearn: 0.2589497\ttotal: 16.2s\tremaining: 7.36s\n",
      "688:\tlearn: 0.2589220\ttotal: 16.2s\tremaining: 7.33s\n",
      "689:\tlearn: 0.2588995\ttotal: 16.3s\tremaining: 7.31s\n",
      "690:\tlearn: 0.2588745\ttotal: 16.3s\tremaining: 7.29s\n",
      "691:\tlearn: 0.2588533\ttotal: 16.3s\tremaining: 7.26s\n",
      "692:\tlearn: 0.2588337\ttotal: 16.3s\tremaining: 7.24s\n",
      "693:\tlearn: 0.2588206\ttotal: 16.4s\tremaining: 7.22s\n",
      "694:\tlearn: 0.2587875\ttotal: 16.4s\tremaining: 7.19s\n",
      "695:\tlearn: 0.2587693\ttotal: 16.4s\tremaining: 7.17s\n",
      "696:\tlearn: 0.2587539\ttotal: 16.4s\tremaining: 7.14s\n",
      "697:\tlearn: 0.2587365\ttotal: 16.4s\tremaining: 7.12s\n",
      "698:\tlearn: 0.2586651\ttotal: 16.5s\tremaining: 7.09s\n",
      "699:\tlearn: 0.2586484\ttotal: 16.5s\tremaining: 7.07s\n",
      "700:\tlearn: 0.2586235\ttotal: 16.5s\tremaining: 7.04s\n",
      "701:\tlearn: 0.2586106\ttotal: 16.5s\tremaining: 7.02s\n",
      "702:\tlearn: 0.2585984\ttotal: 16.6s\tremaining: 7s\n",
      "703:\tlearn: 0.2585822\ttotal: 16.6s\tremaining: 6.97s\n",
      "704:\tlearn: 0.2585683\ttotal: 16.6s\tremaining: 6.95s\n",
      "705:\tlearn: 0.2585477\ttotal: 16.6s\tremaining: 6.93s\n",
      "706:\tlearn: 0.2585335\ttotal: 16.7s\tremaining: 6.9s\n",
      "707:\tlearn: 0.2585178\ttotal: 16.7s\tremaining: 6.88s\n",
      "708:\tlearn: 0.2584988\ttotal: 16.7s\tremaining: 6.85s\n",
      "709:\tlearn: 0.2584858\ttotal: 16.7s\tremaining: 6.83s\n",
      "710:\tlearn: 0.2584703\ttotal: 16.7s\tremaining: 6.8s\n",
      "711:\tlearn: 0.2584478\ttotal: 16.8s\tremaining: 6.78s\n",
      "712:\tlearn: 0.2584316\ttotal: 16.8s\tremaining: 6.76s\n",
      "713:\tlearn: 0.2584080\ttotal: 16.8s\tremaining: 6.74s\n",
      "714:\tlearn: 0.2583915\ttotal: 16.8s\tremaining: 6.71s\n",
      "715:\tlearn: 0.2583337\ttotal: 16.9s\tremaining: 6.69s\n",
      "716:\tlearn: 0.2583114\ttotal: 16.9s\tremaining: 6.67s\n",
      "717:\tlearn: 0.2582917\ttotal: 16.9s\tremaining: 6.64s\n",
      "718:\tlearn: 0.2582760\ttotal: 16.9s\tremaining: 6.62s\n",
      "719:\tlearn: 0.2582615\ttotal: 16.9s\tremaining: 6.59s\n",
      "720:\tlearn: 0.2582449\ttotal: 17s\tremaining: 6.56s\n",
      "721:\tlearn: 0.2581998\ttotal: 17s\tremaining: 6.54s\n",
      "722:\tlearn: 0.2581735\ttotal: 17s\tremaining: 6.52s\n",
      "723:\tlearn: 0.2581567\ttotal: 17s\tremaining: 6.5s\n",
      "724:\tlearn: 0.2581434\ttotal: 17.1s\tremaining: 6.47s\n",
      "725:\tlearn: 0.2581177\ttotal: 17.1s\tremaining: 6.45s\n",
      "726:\tlearn: 0.2581036\ttotal: 17.1s\tremaining: 6.42s\n",
      "727:\tlearn: 0.2580817\ttotal: 17.1s\tremaining: 6.4s\n",
      "728:\tlearn: 0.2580689\ttotal: 17.2s\tremaining: 6.38s\n",
      "729:\tlearn: 0.2580474\ttotal: 17.2s\tremaining: 6.35s\n",
      "730:\tlearn: 0.2580351\ttotal: 17.2s\tremaining: 6.33s\n",
      "731:\tlearn: 0.2580219\ttotal: 17.2s\tremaining: 6.31s\n",
      "732:\tlearn: 0.2579917\ttotal: 17.3s\tremaining: 6.28s\n",
      "733:\tlearn: 0.2579786\ttotal: 17.3s\tremaining: 6.26s\n",
      "734:\tlearn: 0.2579303\ttotal: 17.3s\tremaining: 6.24s\n",
      "735:\tlearn: 0.2579161\ttotal: 17.3s\tremaining: 6.21s\n",
      "736:\tlearn: 0.2578953\ttotal: 17.3s\tremaining: 6.19s\n",
      "737:\tlearn: 0.2578824\ttotal: 17.4s\tremaining: 6.17s\n",
      "738:\tlearn: 0.2578628\ttotal: 17.4s\tremaining: 6.14s\n",
      "739:\tlearn: 0.2578460\ttotal: 17.4s\tremaining: 6.12s\n",
      "740:\tlearn: 0.2578343\ttotal: 17.4s\tremaining: 6.09s\n",
      "741:\tlearn: 0.2578191\ttotal: 17.5s\tremaining: 6.07s\n",
      "742:\tlearn: 0.2578070\ttotal: 17.5s\tremaining: 6.05s\n",
      "743:\tlearn: 0.2577920\ttotal: 17.5s\tremaining: 6.03s\n",
      "744:\tlearn: 0.2577681\ttotal: 17.5s\tremaining: 6s\n",
      "745:\tlearn: 0.2577544\ttotal: 17.6s\tremaining: 5.98s\n",
      "746:\tlearn: 0.2577396\ttotal: 17.6s\tremaining: 5.95s\n",
      "747:\tlearn: 0.2577253\ttotal: 17.6s\tremaining: 5.93s\n",
      "748:\tlearn: 0.2577108\ttotal: 17.6s\tremaining: 5.9s\n",
      "749:\tlearn: 0.2576961\ttotal: 17.6s\tremaining: 5.88s\n",
      "750:\tlearn: 0.2576316\ttotal: 17.7s\tremaining: 5.86s\n",
      "751:\tlearn: 0.2576155\ttotal: 17.7s\tremaining: 5.83s\n",
      "752:\tlearn: 0.2576040\ttotal: 17.7s\tremaining: 5.81s\n",
      "753:\tlearn: 0.2575903\ttotal: 17.7s\tremaining: 5.79s\n",
      "754:\tlearn: 0.2575418\ttotal: 17.8s\tremaining: 5.76s\n",
      "755:\tlearn: 0.2575180\ttotal: 17.8s\tremaining: 5.74s\n",
      "756:\tlearn: 0.2575022\ttotal: 17.8s\tremaining: 5.71s\n",
      "757:\tlearn: 0.2574877\ttotal: 17.8s\tremaining: 5.69s\n",
      "758:\tlearn: 0.2574177\ttotal: 17.8s\tremaining: 5.67s\n",
      "759:\tlearn: 0.2574039\ttotal: 17.9s\tremaining: 5.64s\n",
      "760:\tlearn: 0.2573928\ttotal: 17.9s\tremaining: 5.62s\n",
      "761:\tlearn: 0.2573696\ttotal: 17.9s\tremaining: 5.6s\n",
      "762:\tlearn: 0.2573510\ttotal: 17.9s\tremaining: 5.57s\n",
      "763:\tlearn: 0.2573208\ttotal: 18s\tremaining: 5.55s\n",
      "764:\tlearn: 0.2573042\ttotal: 18s\tremaining: 5.52s\n",
      "765:\tlearn: 0.2572823\ttotal: 18s\tremaining: 5.5s\n",
      "766:\tlearn: 0.2572697\ttotal: 18s\tremaining: 5.48s\n",
      "767:\tlearn: 0.2572030\ttotal: 18.1s\tremaining: 5.45s\n",
      "768:\tlearn: 0.2571682\ttotal: 18.1s\tremaining: 5.43s\n",
      "769:\tlearn: 0.2571521\ttotal: 18.1s\tremaining: 5.41s\n",
      "770:\tlearn: 0.2571268\ttotal: 18.1s\tremaining: 5.39s\n",
      "771:\tlearn: 0.2570974\ttotal: 18.2s\tremaining: 5.36s\n",
      "772:\tlearn: 0.2570547\ttotal: 18.2s\tremaining: 5.34s\n",
      "773:\tlearn: 0.2570283\ttotal: 18.2s\tremaining: 5.31s\n",
      "774:\tlearn: 0.2570165\ttotal: 18.2s\tremaining: 5.29s\n",
      "775:\tlearn: 0.2570012\ttotal: 18.2s\tremaining: 5.26s\n",
      "776:\tlearn: 0.2569887\ttotal: 18.3s\tremaining: 5.24s\n",
      "777:\tlearn: 0.2569754\ttotal: 18.3s\tremaining: 5.22s\n",
      "778:\tlearn: 0.2569589\ttotal: 18.3s\tremaining: 5.19s\n",
      "779:\tlearn: 0.2569444\ttotal: 18.3s\tremaining: 5.17s\n",
      "780:\tlearn: 0.2569295\ttotal: 18.4s\tremaining: 5.15s\n",
      "781:\tlearn: 0.2569176\ttotal: 18.4s\tremaining: 5.12s\n",
      "782:\tlearn: 0.2569076\ttotal: 18.4s\tremaining: 5.1s\n",
      "783:\tlearn: 0.2568853\ttotal: 18.4s\tremaining: 5.07s\n",
      "784:\tlearn: 0.2568569\ttotal: 18.4s\tremaining: 5.05s\n",
      "785:\tlearn: 0.2568430\ttotal: 18.5s\tremaining: 5.02s\n",
      "786:\tlearn: 0.2568137\ttotal: 18.5s\tremaining: 5s\n",
      "787:\tlearn: 0.2567895\ttotal: 18.5s\tremaining: 4.98s\n",
      "788:\tlearn: 0.2567742\ttotal: 18.5s\tremaining: 4.96s\n",
      "789:\tlearn: 0.2567562\ttotal: 18.5s\tremaining: 4.93s\n",
      "790:\tlearn: 0.2567398\ttotal: 18.6s\tremaining: 4.91s\n",
      "791:\tlearn: 0.2567271\ttotal: 18.6s\tremaining: 4.88s\n",
      "792:\tlearn: 0.2567145\ttotal: 18.6s\tremaining: 4.86s\n",
      "793:\tlearn: 0.2566909\ttotal: 18.6s\tremaining: 4.83s\n",
      "794:\tlearn: 0.2566667\ttotal: 18.6s\tremaining: 4.81s\n",
      "795:\tlearn: 0.2566520\ttotal: 18.7s\tremaining: 4.78s\n",
      "796:\tlearn: 0.2566357\ttotal: 18.7s\tremaining: 4.76s\n",
      "797:\tlearn: 0.2566250\ttotal: 18.7s\tremaining: 4.73s\n",
      "798:\tlearn: 0.2566034\ttotal: 18.7s\tremaining: 4.71s\n",
      "799:\tlearn: 0.2565601\ttotal: 18.7s\tremaining: 4.69s\n",
      "800:\tlearn: 0.2565466\ttotal: 18.8s\tremaining: 4.66s\n",
      "801:\tlearn: 0.2565318\ttotal: 18.8s\tremaining: 4.64s\n",
      "802:\tlearn: 0.2565174\ttotal: 18.8s\tremaining: 4.61s\n",
      "803:\tlearn: 0.2565073\ttotal: 18.8s\tremaining: 4.59s\n",
      "804:\tlearn: 0.2564936\ttotal: 18.8s\tremaining: 4.57s\n",
      "805:\tlearn: 0.2564694\ttotal: 18.9s\tremaining: 4.54s\n",
      "806:\tlearn: 0.2564479\ttotal: 18.9s\tremaining: 4.52s\n",
      "807:\tlearn: 0.2564381\ttotal: 18.9s\tremaining: 4.5s\n",
      "808:\tlearn: 0.2564215\ttotal: 19s\tremaining: 4.47s\n",
      "809:\tlearn: 0.2564056\ttotal: 19s\tremaining: 4.45s\n",
      "810:\tlearn: 0.2563872\ttotal: 19s\tremaining: 4.43s\n",
      "811:\tlearn: 0.2563680\ttotal: 19s\tremaining: 4.4s\n",
      "812:\tlearn: 0.2563516\ttotal: 19s\tremaining: 4.38s\n",
      "813:\tlearn: 0.2563387\ttotal: 19.1s\tremaining: 4.36s\n",
      "814:\tlearn: 0.2563234\ttotal: 19.1s\tremaining: 4.33s\n",
      "815:\tlearn: 0.2562654\ttotal: 19.1s\tremaining: 4.31s\n",
      "816:\tlearn: 0.2562503\ttotal: 19.1s\tremaining: 4.28s\n",
      "817:\tlearn: 0.2562325\ttotal: 19.1s\tremaining: 4.26s\n",
      "818:\tlearn: 0.2562128\ttotal: 19.2s\tremaining: 4.24s\n",
      "819:\tlearn: 0.2561965\ttotal: 19.2s\tremaining: 4.21s\n",
      "820:\tlearn: 0.2561684\ttotal: 19.2s\tremaining: 4.19s\n",
      "821:\tlearn: 0.2561539\ttotal: 19.2s\tremaining: 4.17s\n",
      "822:\tlearn: 0.2561411\ttotal: 19.3s\tremaining: 4.14s\n",
      "823:\tlearn: 0.2561287\ttotal: 19.3s\tremaining: 4.12s\n",
      "824:\tlearn: 0.2561093\ttotal: 19.3s\tremaining: 4.09s\n",
      "825:\tlearn: 0.2560982\ttotal: 19.3s\tremaining: 4.07s\n",
      "826:\tlearn: 0.2560898\ttotal: 19.4s\tremaining: 4.05s\n",
      "827:\tlearn: 0.2560797\ttotal: 19.4s\tremaining: 4.03s\n",
      "828:\tlearn: 0.2560655\ttotal: 19.4s\tremaining: 4s\n",
      "829:\tlearn: 0.2560544\ttotal: 19.4s\tremaining: 3.98s\n",
      "830:\tlearn: 0.2560432\ttotal: 19.4s\tremaining: 3.95s\n",
      "831:\tlearn: 0.2560301\ttotal: 19.5s\tremaining: 3.93s\n",
      "832:\tlearn: 0.2560082\ttotal: 19.5s\tremaining: 3.91s\n",
      "833:\tlearn: 0.2559957\ttotal: 19.5s\tremaining: 3.88s\n",
      "834:\tlearn: 0.2559789\ttotal: 19.5s\tremaining: 3.86s\n",
      "835:\tlearn: 0.2559671\ttotal: 19.6s\tremaining: 3.84s\n",
      "836:\tlearn: 0.2559536\ttotal: 19.6s\tremaining: 3.81s\n",
      "837:\tlearn: 0.2559396\ttotal: 19.6s\tremaining: 3.79s\n",
      "838:\tlearn: 0.2559286\ttotal: 19.6s\tremaining: 3.77s\n",
      "839:\tlearn: 0.2559179\ttotal: 19.6s\tremaining: 3.74s\n",
      "840:\tlearn: 0.2559013\ttotal: 19.7s\tremaining: 3.72s\n",
      "841:\tlearn: 0.2558875\ttotal: 19.7s\tremaining: 3.69s\n",
      "842:\tlearn: 0.2558609\ttotal: 19.7s\tremaining: 3.67s\n",
      "843:\tlearn: 0.2558371\ttotal: 19.7s\tremaining: 3.65s\n",
      "844:\tlearn: 0.2557982\ttotal: 19.8s\tremaining: 3.63s\n",
      "845:\tlearn: 0.2557866\ttotal: 19.8s\tremaining: 3.6s\n",
      "846:\tlearn: 0.2557751\ttotal: 19.8s\tremaining: 3.58s\n",
      "847:\tlearn: 0.2557661\ttotal: 19.8s\tremaining: 3.56s\n",
      "848:\tlearn: 0.2557428\ttotal: 19.9s\tremaining: 3.53s\n",
      "849:\tlearn: 0.2557305\ttotal: 19.9s\tremaining: 3.51s\n",
      "850:\tlearn: 0.2557095\ttotal: 19.9s\tremaining: 3.48s\n",
      "851:\tlearn: 0.2556792\ttotal: 19.9s\tremaining: 3.46s\n",
      "852:\tlearn: 0.2556665\ttotal: 19.9s\tremaining: 3.44s\n",
      "853:\tlearn: 0.2556430\ttotal: 20s\tremaining: 3.41s\n",
      "854:\tlearn: 0.2556316\ttotal: 20s\tremaining: 3.39s\n",
      "855:\tlearn: 0.2556174\ttotal: 20s\tremaining: 3.37s\n",
      "856:\tlearn: 0.2556027\ttotal: 20s\tremaining: 3.34s\n",
      "857:\tlearn: 0.2555887\ttotal: 20.1s\tremaining: 3.32s\n",
      "858:\tlearn: 0.2555781\ttotal: 20.1s\tremaining: 3.3s\n",
      "859:\tlearn: 0.2555284\ttotal: 20.1s\tremaining: 3.27s\n",
      "860:\tlearn: 0.2555164\ttotal: 20.1s\tremaining: 3.25s\n",
      "861:\tlearn: 0.2555000\ttotal: 20.1s\tremaining: 3.22s\n",
      "862:\tlearn: 0.2554886\ttotal: 20.2s\tremaining: 3.2s\n",
      "863:\tlearn: 0.2554800\ttotal: 20.2s\tremaining: 3.18s\n",
      "864:\tlearn: 0.2554667\ttotal: 20.2s\tremaining: 3.15s\n",
      "865:\tlearn: 0.2554572\ttotal: 20.2s\tremaining: 3.13s\n",
      "866:\tlearn: 0.2554296\ttotal: 20.3s\tremaining: 3.11s\n",
      "867:\tlearn: 0.2554098\ttotal: 20.3s\tremaining: 3.08s\n",
      "868:\tlearn: 0.2553981\ttotal: 20.3s\tremaining: 3.06s\n",
      "869:\tlearn: 0.2553857\ttotal: 20.3s\tremaining: 3.04s\n",
      "870:\tlearn: 0.2553563\ttotal: 20.3s\tremaining: 3.01s\n",
      "871:\tlearn: 0.2553441\ttotal: 20.4s\tremaining: 2.99s\n",
      "872:\tlearn: 0.2553310\ttotal: 20.4s\tremaining: 2.96s\n",
      "873:\tlearn: 0.2553176\ttotal: 20.4s\tremaining: 2.94s\n",
      "874:\tlearn: 0.2553066\ttotal: 20.4s\tremaining: 2.92s\n",
      "875:\tlearn: 0.2552912\ttotal: 20.5s\tremaining: 2.9s\n",
      "876:\tlearn: 0.2552788\ttotal: 20.5s\tremaining: 2.87s\n",
      "877:\tlearn: 0.2552586\ttotal: 20.5s\tremaining: 2.85s\n",
      "878:\tlearn: 0.2552474\ttotal: 20.5s\tremaining: 2.82s\n",
      "879:\tlearn: 0.2552269\ttotal: 20.5s\tremaining: 2.8s\n",
      "880:\tlearn: 0.2552197\ttotal: 20.6s\tremaining: 2.78s\n",
      "881:\tlearn: 0.2552011\ttotal: 20.6s\tremaining: 2.75s\n",
      "882:\tlearn: 0.2551891\ttotal: 20.6s\tremaining: 2.73s\n",
      "883:\tlearn: 0.2551775\ttotal: 20.6s\tremaining: 2.71s\n",
      "884:\tlearn: 0.2551669\ttotal: 20.7s\tremaining: 2.68s\n",
      "885:\tlearn: 0.2551526\ttotal: 20.7s\tremaining: 2.66s\n",
      "886:\tlearn: 0.2551423\ttotal: 20.7s\tremaining: 2.64s\n",
      "887:\tlearn: 0.2551327\ttotal: 20.7s\tremaining: 2.61s\n",
      "888:\tlearn: 0.2551195\ttotal: 20.7s\tremaining: 2.59s\n",
      "889:\tlearn: 0.2551091\ttotal: 20.8s\tremaining: 2.56s\n",
      "890:\tlearn: 0.2550962\ttotal: 20.8s\tremaining: 2.54s\n",
      "891:\tlearn: 0.2550804\ttotal: 20.8s\tremaining: 2.52s\n",
      "892:\tlearn: 0.2550697\ttotal: 20.8s\tremaining: 2.5s\n",
      "893:\tlearn: 0.2550574\ttotal: 20.9s\tremaining: 2.47s\n",
      "894:\tlearn: 0.2550463\ttotal: 20.9s\tremaining: 2.45s\n",
      "895:\tlearn: 0.2550385\ttotal: 20.9s\tremaining: 2.43s\n",
      "896:\tlearn: 0.2550291\ttotal: 20.9s\tremaining: 2.4s\n",
      "897:\tlearn: 0.2549981\ttotal: 20.9s\tremaining: 2.38s\n",
      "898:\tlearn: 0.2549854\ttotal: 21s\tremaining: 2.36s\n",
      "899:\tlearn: 0.2549725\ttotal: 21s\tremaining: 2.33s\n",
      "900:\tlearn: 0.2549615\ttotal: 21s\tremaining: 2.31s\n",
      "901:\tlearn: 0.2549396\ttotal: 21s\tremaining: 2.29s\n",
      "902:\tlearn: 0.2549271\ttotal: 21.1s\tremaining: 2.26s\n",
      "903:\tlearn: 0.2549163\ttotal: 21.1s\tremaining: 2.24s\n",
      "904:\tlearn: 0.2549065\ttotal: 21.1s\tremaining: 2.22s\n",
      "905:\tlearn: 0.2548962\ttotal: 21.2s\tremaining: 2.19s\n",
      "906:\tlearn: 0.2548839\ttotal: 21.2s\tremaining: 2.17s\n",
      "907:\tlearn: 0.2548725\ttotal: 21.2s\tremaining: 2.15s\n",
      "908:\tlearn: 0.2548628\ttotal: 21.2s\tremaining: 2.12s\n",
      "909:\tlearn: 0.2548503\ttotal: 21.2s\tremaining: 2.1s\n",
      "910:\tlearn: 0.2548414\ttotal: 21.3s\tremaining: 2.08s\n",
      "911:\tlearn: 0.2548335\ttotal: 21.3s\tremaining: 2.05s\n",
      "912:\tlearn: 0.2548115\ttotal: 21.3s\tremaining: 2.03s\n",
      "913:\tlearn: 0.2547992\ttotal: 21.3s\tremaining: 2.01s\n",
      "914:\tlearn: 0.2547812\ttotal: 21.4s\tremaining: 1.98s\n",
      "915:\tlearn: 0.2547720\ttotal: 21.4s\tremaining: 1.96s\n",
      "916:\tlearn: 0.2547632\ttotal: 21.4s\tremaining: 1.94s\n",
      "917:\tlearn: 0.2547520\ttotal: 21.4s\tremaining: 1.91s\n",
      "918:\tlearn: 0.2547306\ttotal: 21.5s\tremaining: 1.89s\n",
      "919:\tlearn: 0.2547233\ttotal: 21.5s\tremaining: 1.87s\n",
      "920:\tlearn: 0.2547117\ttotal: 21.5s\tremaining: 1.84s\n",
      "921:\tlearn: 0.2547018\ttotal: 21.5s\tremaining: 1.82s\n",
      "922:\tlearn: 0.2546909\ttotal: 21.6s\tremaining: 1.8s\n",
      "923:\tlearn: 0.2546617\ttotal: 21.6s\tremaining: 1.78s\n",
      "924:\tlearn: 0.2546502\ttotal: 21.6s\tremaining: 1.75s\n",
      "925:\tlearn: 0.2546407\ttotal: 21.6s\tremaining: 1.73s\n",
      "926:\tlearn: 0.2546290\ttotal: 21.7s\tremaining: 1.71s\n",
      "927:\tlearn: 0.2545959\ttotal: 21.7s\tremaining: 1.68s\n",
      "928:\tlearn: 0.2545841\ttotal: 21.7s\tremaining: 1.66s\n",
      "929:\tlearn: 0.2545751\ttotal: 21.7s\tremaining: 1.64s\n",
      "930:\tlearn: 0.2545656\ttotal: 21.8s\tremaining: 1.61s\n",
      "931:\tlearn: 0.2545152\ttotal: 21.8s\tremaining: 1.59s\n",
      "932:\tlearn: 0.2544991\ttotal: 21.8s\tremaining: 1.57s\n",
      "933:\tlearn: 0.2544910\ttotal: 21.8s\tremaining: 1.54s\n",
      "934:\tlearn: 0.2544816\ttotal: 21.9s\tremaining: 1.52s\n",
      "935:\tlearn: 0.2544662\ttotal: 21.9s\tremaining: 1.5s\n",
      "936:\tlearn: 0.2544192\ttotal: 21.9s\tremaining: 1.47s\n",
      "937:\tlearn: 0.2544077\ttotal: 21.9s\tremaining: 1.45s\n",
      "938:\tlearn: 0.2543842\ttotal: 21.9s\tremaining: 1.43s\n",
      "939:\tlearn: 0.2543627\ttotal: 22s\tremaining: 1.4s\n",
      "940:\tlearn: 0.2543435\ttotal: 22s\tremaining: 1.38s\n",
      "941:\tlearn: 0.2543321\ttotal: 22s\tremaining: 1.35s\n",
      "942:\tlearn: 0.2543166\ttotal: 22s\tremaining: 1.33s\n",
      "943:\tlearn: 0.2543063\ttotal: 22.1s\tremaining: 1.31s\n",
      "944:\tlearn: 0.2542849\ttotal: 22.1s\tremaining: 1.28s\n",
      "945:\tlearn: 0.2542747\ttotal: 22.1s\tremaining: 1.26s\n",
      "946:\tlearn: 0.2542598\ttotal: 22.1s\tremaining: 1.24s\n",
      "947:\tlearn: 0.2542485\ttotal: 22.2s\tremaining: 1.22s\n",
      "948:\tlearn: 0.2542384\ttotal: 22.2s\tremaining: 1.19s\n",
      "949:\tlearn: 0.2542176\ttotal: 22.2s\tremaining: 1.17s\n",
      "950:\tlearn: 0.2542102\ttotal: 22.2s\tremaining: 1.15s\n",
      "951:\tlearn: 0.2542020\ttotal: 22.3s\tremaining: 1.12s\n",
      "952:\tlearn: 0.2541798\ttotal: 22.3s\tremaining: 1.1s\n",
      "953:\tlearn: 0.2541703\ttotal: 22.3s\tremaining: 1.07s\n",
      "954:\tlearn: 0.2541512\ttotal: 22.3s\tremaining: 1.05s\n",
      "955:\tlearn: 0.2541371\ttotal: 22.3s\tremaining: 1.03s\n",
      "956:\tlearn: 0.2541276\ttotal: 22.4s\tremaining: 1s\n",
      "957:\tlearn: 0.2541152\ttotal: 22.4s\tremaining: 982ms\n",
      "958:\tlearn: 0.2541001\ttotal: 22.4s\tremaining: 959ms\n",
      "959:\tlearn: 0.2540892\ttotal: 22.4s\tremaining: 935ms\n",
      "960:\tlearn: 0.2540791\ttotal: 22.5s\tremaining: 912ms\n",
      "961:\tlearn: 0.2540642\ttotal: 22.5s\tremaining: 888ms\n",
      "962:\tlearn: 0.2540543\ttotal: 22.5s\tremaining: 865ms\n",
      "963:\tlearn: 0.2540445\ttotal: 22.5s\tremaining: 842ms\n",
      "964:\tlearn: 0.2540359\ttotal: 22.6s\tremaining: 818ms\n",
      "965:\tlearn: 0.2540261\ttotal: 22.6s\tremaining: 795ms\n",
      "966:\tlearn: 0.2540101\ttotal: 22.6s\tremaining: 771ms\n",
      "967:\tlearn: 0.2539985\ttotal: 22.6s\tremaining: 748ms\n",
      "968:\tlearn: 0.2539870\ttotal: 22.7s\tremaining: 725ms\n",
      "969:\tlearn: 0.2539620\ttotal: 22.7s\tremaining: 701ms\n",
      "970:\tlearn: 0.2539441\ttotal: 22.7s\tremaining: 678ms\n",
      "971:\tlearn: 0.2539303\ttotal: 22.7s\tremaining: 654ms\n",
      "972:\tlearn: 0.2539205\ttotal: 22.7s\tremaining: 631ms\n",
      "973:\tlearn: 0.2538967\ttotal: 22.8s\tremaining: 608ms\n",
      "974:\tlearn: 0.2538814\ttotal: 22.8s\tremaining: 584ms\n",
      "975:\tlearn: 0.2538619\ttotal: 22.8s\tremaining: 561ms\n",
      "976:\tlearn: 0.2538516\ttotal: 22.8s\tremaining: 538ms\n",
      "977:\tlearn: 0.2538219\ttotal: 22.9s\tremaining: 514ms\n",
      "978:\tlearn: 0.2538134\ttotal: 22.9s\tremaining: 491ms\n",
      "979:\tlearn: 0.2538048\ttotal: 22.9s\tremaining: 467ms\n",
      "980:\tlearn: 0.2537969\ttotal: 22.9s\tremaining: 444ms\n",
      "981:\tlearn: 0.2537890\ttotal: 23s\tremaining: 421ms\n",
      "982:\tlearn: 0.2537679\ttotal: 23s\tremaining: 397ms\n",
      "983:\tlearn: 0.2537585\ttotal: 23s\tremaining: 374ms\n",
      "984:\tlearn: 0.2537190\ttotal: 23s\tremaining: 351ms\n",
      "985:\tlearn: 0.2537105\ttotal: 23.1s\tremaining: 328ms\n",
      "986:\tlearn: 0.2536987\ttotal: 23.1s\tremaining: 304ms\n",
      "987:\tlearn: 0.2536808\ttotal: 23.1s\tremaining: 281ms\n",
      "988:\tlearn: 0.2536694\ttotal: 23.1s\tremaining: 257ms\n",
      "989:\tlearn: 0.2536478\ttotal: 23.1s\tremaining: 234ms\n",
      "990:\tlearn: 0.2536349\ttotal: 23.2s\tremaining: 210ms\n",
      "991:\tlearn: 0.2536271\ttotal: 23.2s\tremaining: 187ms\n",
      "992:\tlearn: 0.2536186\ttotal: 23.2s\tremaining: 164ms\n",
      "993:\tlearn: 0.2536051\ttotal: 23.2s\tremaining: 140ms\n",
      "994:\tlearn: 0.2535941\ttotal: 23.3s\tremaining: 117ms\n",
      "995:\tlearn: 0.2535830\ttotal: 23.3s\tremaining: 93.5ms\n",
      "996:\tlearn: 0.2535739\ttotal: 23.3s\tremaining: 70.1ms\n",
      "997:\tlearn: 0.2535689\ttotal: 23.3s\tremaining: 46.8ms\n",
      "998:\tlearn: 0.2535579\ttotal: 23.4s\tremaining: 23.4ms\n",
      "999:\tlearn: 0.2535514\ttotal: 23.4s\tremaining: 0us\n",
      "Best score: 88.69%\n",
      "Best Hyperparameters:{'depth': 5, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "cat_parameters = {'depth' : [5, 10],'learning_rate' : [0.01, 0.05, 0.1, 0.3]}\n",
    "cross_val(cat, cat_parameters, X_train_pre, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".2607513\ttotal: 22.4s\tremaining: 13.6s\n",
      "622:\tlearn: 0.2607373\ttotal: 22.4s\tremaining: 13.5s\n",
      "623:\tlearn: 0.2607167\ttotal: 22.4s\tremaining: 13.5s\n",
      "624:\tlearn: 0.2606130\ttotal: 22.4s\tremaining: 13.5s\n",
      "625:\tlearn: 0.2605958\ttotal: 22.5s\tremaining: 13.4s\n",
      "626:\tlearn: 0.2605748\ttotal: 22.5s\tremaining: 13.4s\n",
      "627:\tlearn: 0.2605550\ttotal: 22.5s\tremaining: 13.4s\n",
      "628:\tlearn: 0.2605402\ttotal: 22.6s\tremaining: 13.3s\n",
      "629:\tlearn: 0.2605204\ttotal: 22.6s\tremaining: 13.3s\n",
      "630:\tlearn: 0.2604692\ttotal: 22.6s\tremaining: 13.2s\n",
      "631:\tlearn: 0.2603825\ttotal: 22.6s\tremaining: 13.2s\n",
      "632:\tlearn: 0.2603653\ttotal: 22.7s\tremaining: 13.1s\n",
      "633:\tlearn: 0.2603449\ttotal: 22.7s\tremaining: 13.1s\n",
      "634:\tlearn: 0.2603294\ttotal: 22.7s\tremaining: 13.1s\n",
      "635:\tlearn: 0.2603152\ttotal: 22.7s\tremaining: 13s\n",
      "636:\tlearn: 0.2602977\ttotal: 22.8s\tremaining: 13s\n",
      "637:\tlearn: 0.2602663\ttotal: 22.8s\tremaining: 12.9s\n",
      "638:\tlearn: 0.2602372\ttotal: 22.8s\tremaining: 12.9s\n",
      "639:\tlearn: 0.2602184\ttotal: 22.8s\tremaining: 12.8s\n",
      "640:\tlearn: 0.2601475\ttotal: 22.9s\tremaining: 12.8s\n",
      "641:\tlearn: 0.2600932\ttotal: 22.9s\tremaining: 12.8s\n",
      "642:\tlearn: 0.2600636\ttotal: 22.9s\tremaining: 12.7s\n",
      "643:\tlearn: 0.2600445\ttotal: 23s\tremaining: 12.7s\n",
      "644:\tlearn: 0.2600271\ttotal: 23s\tremaining: 12.7s\n",
      "645:\tlearn: 0.2600047\ttotal: 23s\tremaining: 12.6s\n",
      "646:\tlearn: 0.2599838\ttotal: 23s\tremaining: 12.6s\n",
      "647:\tlearn: 0.2599657\ttotal: 23.1s\tremaining: 12.5s\n",
      "648:\tlearn: 0.2598855\ttotal: 23.1s\tremaining: 12.5s\n",
      "649:\tlearn: 0.2598622\ttotal: 23.1s\tremaining: 12.5s\n",
      "650:\tlearn: 0.2598418\ttotal: 23.2s\tremaining: 12.4s\n",
      "651:\tlearn: 0.2598176\ttotal: 23.2s\tremaining: 12.4s\n",
      "652:\tlearn: 0.2597970\ttotal: 23.2s\tremaining: 12.3s\n",
      "653:\tlearn: 0.2597797\ttotal: 23.3s\tremaining: 12.3s\n",
      "654:\tlearn: 0.2597554\ttotal: 23.3s\tremaining: 12.3s\n",
      "655:\tlearn: 0.2597360\ttotal: 23.3s\tremaining: 12.2s\n",
      "656:\tlearn: 0.2597241\ttotal: 23.3s\tremaining: 12.2s\n",
      "657:\tlearn: 0.2597061\ttotal: 23.4s\tremaining: 12.1s\n",
      "658:\tlearn: 0.2596893\ttotal: 23.4s\tremaining: 12.1s\n",
      "659:\tlearn: 0.2596613\ttotal: 23.4s\tremaining: 12.1s\n",
      "660:\tlearn: 0.2596324\ttotal: 23.4s\tremaining: 12s\n",
      "661:\tlearn: 0.2596086\ttotal: 23.5s\tremaining: 12s\n",
      "662:\tlearn: 0.2595839\ttotal: 23.5s\tremaining: 11.9s\n",
      "663:\tlearn: 0.2594965\ttotal: 23.5s\tremaining: 11.9s\n",
      "664:\tlearn: 0.2594794\ttotal: 23.6s\tremaining: 11.9s\n",
      "665:\tlearn: 0.2594650\ttotal: 23.6s\tremaining: 11.8s\n",
      "666:\tlearn: 0.2594339\ttotal: 23.6s\tremaining: 11.8s\n",
      "667:\tlearn: 0.2594113\ttotal: 23.6s\tremaining: 11.8s\n",
      "668:\tlearn: 0.2593947\ttotal: 23.7s\tremaining: 11.7s\n",
      "669:\tlearn: 0.2593764\ttotal: 23.7s\tremaining: 11.7s\n",
      "670:\tlearn: 0.2593428\ttotal: 23.7s\tremaining: 11.6s\n",
      "671:\tlearn: 0.2593252\ttotal: 23.8s\tremaining: 11.6s\n",
      "672:\tlearn: 0.2592897\ttotal: 23.8s\tremaining: 11.6s\n",
      "673:\tlearn: 0.2592757\ttotal: 23.8s\tremaining: 11.5s\n",
      "674:\tlearn: 0.2592588\ttotal: 23.8s\tremaining: 11.5s\n",
      "675:\tlearn: 0.2592225\ttotal: 23.9s\tremaining: 11.4s\n",
      "676:\tlearn: 0.2592064\ttotal: 23.9s\tremaining: 11.4s\n",
      "677:\tlearn: 0.2591897\ttotal: 23.9s\tremaining: 11.4s\n",
      "678:\tlearn: 0.2591664\ttotal: 23.9s\tremaining: 11.3s\n",
      "679:\tlearn: 0.2591460\ttotal: 24s\tremaining: 11.3s\n",
      "680:\tlearn: 0.2591176\ttotal: 24s\tremaining: 11.2s\n",
      "681:\tlearn: 0.2590947\ttotal: 24s\tremaining: 11.2s\n",
      "682:\tlearn: 0.2590828\ttotal: 24.1s\tremaining: 11.2s\n",
      "683:\tlearn: 0.2590264\ttotal: 24.1s\tremaining: 11.1s\n",
      "684:\tlearn: 0.2590063\ttotal: 24.1s\tremaining: 11.1s\n",
      "685:\tlearn: 0.2589819\ttotal: 24.2s\tremaining: 11.1s\n",
      "686:\tlearn: 0.2589667\ttotal: 24.2s\tremaining: 11s\n",
      "687:\tlearn: 0.2589497\ttotal: 24.3s\tremaining: 11s\n",
      "688:\tlearn: 0.2589220\ttotal: 24.3s\tremaining: 11s\n",
      "689:\tlearn: 0.2588995\ttotal: 24.4s\tremaining: 11s\n",
      "690:\tlearn: 0.2588745\ttotal: 24.4s\tremaining: 10.9s\n",
      "691:\tlearn: 0.2588533\ttotal: 24.5s\tremaining: 10.9s\n",
      "692:\tlearn: 0.2588337\ttotal: 24.5s\tremaining: 10.9s\n",
      "693:\tlearn: 0.2588206\ttotal: 24.6s\tremaining: 10.8s\n",
      "694:\tlearn: 0.2587875\ttotal: 24.6s\tremaining: 10.8s\n",
      "695:\tlearn: 0.2587693\ttotal: 24.6s\tremaining: 10.8s\n",
      "696:\tlearn: 0.2587539\ttotal: 24.7s\tremaining: 10.7s\n",
      "697:\tlearn: 0.2587365\ttotal: 24.7s\tremaining: 10.7s\n",
      "698:\tlearn: 0.2586651\ttotal: 24.7s\tremaining: 10.6s\n",
      "699:\tlearn: 0.2586484\ttotal: 24.8s\tremaining: 10.6s\n",
      "700:\tlearn: 0.2586235\ttotal: 24.8s\tremaining: 10.6s\n",
      "701:\tlearn: 0.2586106\ttotal: 24.8s\tremaining: 10.5s\n",
      "702:\tlearn: 0.2585984\ttotal: 24.8s\tremaining: 10.5s\n",
      "703:\tlearn: 0.2585822\ttotal: 24.9s\tremaining: 10.5s\n",
      "704:\tlearn: 0.2585683\ttotal: 24.9s\tremaining: 10.4s\n",
      "705:\tlearn: 0.2585477\ttotal: 24.9s\tremaining: 10.4s\n",
      "706:\tlearn: 0.2585335\ttotal: 24.9s\tremaining: 10.3s\n",
      "707:\tlearn: 0.2585178\ttotal: 25s\tremaining: 10.3s\n",
      "708:\tlearn: 0.2584988\ttotal: 25s\tremaining: 10.3s\n",
      "709:\tlearn: 0.2584858\ttotal: 25s\tremaining: 10.2s\n",
      "710:\tlearn: 0.2584703\ttotal: 25s\tremaining: 10.2s\n",
      "711:\tlearn: 0.2584478\ttotal: 25.1s\tremaining: 10.1s\n",
      "712:\tlearn: 0.2584316\ttotal: 25.1s\tremaining: 10.1s\n",
      "713:\tlearn: 0.2584080\ttotal: 25.1s\tremaining: 10.1s\n",
      "714:\tlearn: 0.2583915\ttotal: 25.2s\tremaining: 10s\n",
      "715:\tlearn: 0.2583337\ttotal: 25.2s\tremaining: 9.99s\n",
      "716:\tlearn: 0.2583114\ttotal: 25.2s\tremaining: 9.95s\n",
      "717:\tlearn: 0.2582917\ttotal: 25.2s\tremaining: 9.91s\n",
      "718:\tlearn: 0.2582760\ttotal: 25.3s\tremaining: 9.87s\n",
      "719:\tlearn: 0.2582615\ttotal: 25.3s\tremaining: 9.83s\n",
      "720:\tlearn: 0.2582449\ttotal: 25.3s\tremaining: 9.79s\n",
      "721:\tlearn: 0.2581998\ttotal: 25.3s\tremaining: 9.76s\n",
      "722:\tlearn: 0.2581735\ttotal: 25.4s\tremaining: 9.72s\n",
      "723:\tlearn: 0.2581567\ttotal: 25.4s\tremaining: 9.68s\n",
      "724:\tlearn: 0.2581434\ttotal: 25.4s\tremaining: 9.65s\n",
      "725:\tlearn: 0.2581177\ttotal: 25.5s\tremaining: 9.61s\n",
      "726:\tlearn: 0.2581036\ttotal: 25.5s\tremaining: 9.57s\n",
      "727:\tlearn: 0.2580817\ttotal: 25.5s\tremaining: 9.54s\n",
      "728:\tlearn: 0.2580689\ttotal: 25.6s\tremaining: 9.51s\n",
      "729:\tlearn: 0.2580474\ttotal: 25.6s\tremaining: 9.48s\n",
      "730:\tlearn: 0.2580351\ttotal: 25.7s\tremaining: 9.45s\n",
      "731:\tlearn: 0.2580219\ttotal: 25.7s\tremaining: 9.42s\n",
      "732:\tlearn: 0.2579917\ttotal: 25.8s\tremaining: 9.39s\n",
      "733:\tlearn: 0.2579786\ttotal: 25.8s\tremaining: 9.36s\n",
      "734:\tlearn: 0.2579303\ttotal: 25.9s\tremaining: 9.33s\n",
      "735:\tlearn: 0.2579161\ttotal: 25.9s\tremaining: 9.3s\n",
      "736:\tlearn: 0.2578953\ttotal: 26s\tremaining: 9.27s\n",
      "737:\tlearn: 0.2578824\ttotal: 26s\tremaining: 9.23s\n",
      "738:\tlearn: 0.2578628\ttotal: 26.1s\tremaining: 9.2s\n",
      "739:\tlearn: 0.2578460\ttotal: 26.1s\tremaining: 9.17s\n",
      "740:\tlearn: 0.2578343\ttotal: 26.1s\tremaining: 9.14s\n",
      "741:\tlearn: 0.2578191\ttotal: 26.2s\tremaining: 9.1s\n",
      "742:\tlearn: 0.2578070\ttotal: 26.2s\tremaining: 9.06s\n",
      "743:\tlearn: 0.2577920\ttotal: 26.3s\tremaining: 9.03s\n",
      "744:\tlearn: 0.2577681\ttotal: 26.3s\tremaining: 9s\n",
      "745:\tlearn: 0.2577544\ttotal: 26.4s\tremaining: 8.97s\n",
      "746:\tlearn: 0.2577396\ttotal: 26.4s\tremaining: 8.95s\n",
      "747:\tlearn: 0.2577253\ttotal: 26.5s\tremaining: 8.92s\n",
      "748:\tlearn: 0.2577108\ttotal: 26.5s\tremaining: 8.88s\n",
      "749:\tlearn: 0.2576961\ttotal: 26.6s\tremaining: 8.85s\n",
      "750:\tlearn: 0.2576316\ttotal: 26.6s\tremaining: 8.82s\n",
      "751:\tlearn: 0.2576155\ttotal: 26.7s\tremaining: 8.79s\n",
      "752:\tlearn: 0.2576040\ttotal: 26.7s\tremaining: 8.76s\n",
      "753:\tlearn: 0.2575903\ttotal: 26.7s\tremaining: 8.72s\n",
      "754:\tlearn: 0.2575418\ttotal: 26.8s\tremaining: 8.69s\n",
      "755:\tlearn: 0.2575180\ttotal: 26.8s\tremaining: 8.65s\n",
      "756:\tlearn: 0.2575022\ttotal: 26.8s\tremaining: 8.61s\n",
      "757:\tlearn: 0.2574877\ttotal: 26.8s\tremaining: 8.57s\n",
      "758:\tlearn: 0.2574177\ttotal: 26.9s\tremaining: 8.53s\n",
      "759:\tlearn: 0.2574039\ttotal: 26.9s\tremaining: 8.49s\n",
      "760:\tlearn: 0.2573928\ttotal: 26.9s\tremaining: 8.45s\n",
      "761:\tlearn: 0.2573696\ttotal: 26.9s\tremaining: 8.41s\n",
      "762:\tlearn: 0.2573510\ttotal: 27s\tremaining: 8.38s\n",
      "763:\tlearn: 0.2573208\ttotal: 27s\tremaining: 8.34s\n",
      "764:\tlearn: 0.2573042\ttotal: 27s\tremaining: 8.3s\n",
      "765:\tlearn: 0.2572823\ttotal: 27s\tremaining: 8.26s\n",
      "766:\tlearn: 0.2572697\ttotal: 27.1s\tremaining: 8.22s\n",
      "767:\tlearn: 0.2572030\ttotal: 27.1s\tremaining: 8.18s\n",
      "768:\tlearn: 0.2571682\ttotal: 27.1s\tremaining: 8.14s\n",
      "769:\tlearn: 0.2571521\ttotal: 27.1s\tremaining: 8.11s\n",
      "770:\tlearn: 0.2571268\ttotal: 27.2s\tremaining: 8.07s\n",
      "771:\tlearn: 0.2570974\ttotal: 27.2s\tremaining: 8.04s\n",
      "772:\tlearn: 0.2570547\ttotal: 27.2s\tremaining: 8s\n",
      "773:\tlearn: 0.2570283\ttotal: 27.3s\tremaining: 7.96s\n",
      "774:\tlearn: 0.2570165\ttotal: 27.3s\tremaining: 7.92s\n",
      "775:\tlearn: 0.2570012\ttotal: 27.3s\tremaining: 7.88s\n",
      "776:\tlearn: 0.2569887\ttotal: 27.4s\tremaining: 7.85s\n",
      "777:\tlearn: 0.2569754\ttotal: 27.4s\tremaining: 7.81s\n",
      "778:\tlearn: 0.2569589\ttotal: 27.4s\tremaining: 7.77s\n",
      "779:\tlearn: 0.2569444\ttotal: 27.4s\tremaining: 7.74s\n",
      "780:\tlearn: 0.2569295\ttotal: 27.5s\tremaining: 7.7s\n",
      "781:\tlearn: 0.2569176\ttotal: 27.5s\tremaining: 7.66s\n",
      "782:\tlearn: 0.2569076\ttotal: 27.5s\tremaining: 7.62s\n",
      "783:\tlearn: 0.2568853\ttotal: 27.5s\tremaining: 7.59s\n",
      "784:\tlearn: 0.2568569\ttotal: 27.6s\tremaining: 7.55s\n",
      "785:\tlearn: 0.2568430\ttotal: 27.6s\tremaining: 7.51s\n",
      "786:\tlearn: 0.2568137\ttotal: 27.6s\tremaining: 7.48s\n",
      "787:\tlearn: 0.2567895\ttotal: 27.7s\tremaining: 7.44s\n",
      "788:\tlearn: 0.2567742\ttotal: 27.7s\tremaining: 7.4s\n",
      "789:\tlearn: 0.2567562\ttotal: 27.7s\tremaining: 7.37s\n",
      "790:\tlearn: 0.2567398\ttotal: 27.8s\tremaining: 7.34s\n",
      "791:\tlearn: 0.2567271\ttotal: 27.8s\tremaining: 7.31s\n",
      "792:\tlearn: 0.2567145\ttotal: 27.9s\tremaining: 7.27s\n",
      "793:\tlearn: 0.2566909\ttotal: 27.9s\tremaining: 7.24s\n",
      "794:\tlearn: 0.2566667\ttotal: 27.9s\tremaining: 7.21s\n",
      "795:\tlearn: 0.2566520\ttotal: 28s\tremaining: 7.17s\n",
      "796:\tlearn: 0.2566357\ttotal: 28s\tremaining: 7.14s\n",
      "797:\tlearn: 0.2566250\ttotal: 28.1s\tremaining: 7.11s\n",
      "798:\tlearn: 0.2566034\ttotal: 28.1s\tremaining: 7.08s\n",
      "799:\tlearn: 0.2565601\ttotal: 28.2s\tremaining: 7.04s\n",
      "800:\tlearn: 0.2565466\ttotal: 28.2s\tremaining: 7s\n",
      "801:\tlearn: 0.2565318\ttotal: 28.2s\tremaining: 6.97s\n",
      "802:\tlearn: 0.2565174\ttotal: 28.3s\tremaining: 6.93s\n",
      "803:\tlearn: 0.2565073\ttotal: 28.3s\tremaining: 6.9s\n",
      "804:\tlearn: 0.2564936\ttotal: 28.3s\tremaining: 6.86s\n",
      "805:\tlearn: 0.2564694\ttotal: 28.4s\tremaining: 6.83s\n",
      "806:\tlearn: 0.2564479\ttotal: 28.4s\tremaining: 6.79s\n",
      "807:\tlearn: 0.2564381\ttotal: 28.4s\tremaining: 6.75s\n",
      "808:\tlearn: 0.2564215\ttotal: 28.4s\tremaining: 6.71s\n",
      "809:\tlearn: 0.2564056\ttotal: 28.5s\tremaining: 6.68s\n",
      "810:\tlearn: 0.2563872\ttotal: 28.5s\tremaining: 6.65s\n",
      "811:\tlearn: 0.2563680\ttotal: 28.6s\tremaining: 6.62s\n",
      "812:\tlearn: 0.2563516\ttotal: 28.6s\tremaining: 6.58s\n",
      "813:\tlearn: 0.2563387\ttotal: 28.7s\tremaining: 6.55s\n",
      "814:\tlearn: 0.2563234\ttotal: 28.7s\tremaining: 6.52s\n",
      "815:\tlearn: 0.2562654\ttotal: 28.8s\tremaining: 6.49s\n",
      "816:\tlearn: 0.2562503\ttotal: 28.8s\tremaining: 6.46s\n",
      "817:\tlearn: 0.2562325\ttotal: 28.9s\tremaining: 6.42s\n",
      "818:\tlearn: 0.2562128\ttotal: 28.9s\tremaining: 6.39s\n",
      "819:\tlearn: 0.2561965\ttotal: 28.9s\tremaining: 6.35s\n",
      "820:\tlearn: 0.2561684\ttotal: 29s\tremaining: 6.32s\n",
      "821:\tlearn: 0.2561539\ttotal: 29s\tremaining: 6.28s\n",
      "822:\tlearn: 0.2561411\ttotal: 29s\tremaining: 6.24s\n",
      "823:\tlearn: 0.2561287\ttotal: 29.1s\tremaining: 6.21s\n",
      "824:\tlearn: 0.2561093\ttotal: 29.1s\tremaining: 6.17s\n",
      "825:\tlearn: 0.2560982\ttotal: 29.1s\tremaining: 6.13s\n",
      "826:\tlearn: 0.2560898\ttotal: 29.1s\tremaining: 6.1s\n",
      "827:\tlearn: 0.2560797\ttotal: 29.2s\tremaining: 6.06s\n",
      "828:\tlearn: 0.2560655\ttotal: 29.2s\tremaining: 6.03s\n",
      "829:\tlearn: 0.2560544\ttotal: 29.3s\tremaining: 5.99s\n",
      "830:\tlearn: 0.2560432\ttotal: 29.3s\tremaining: 5.96s\n",
      "831:\tlearn: 0.2560301\ttotal: 29.4s\tremaining: 5.93s\n",
      "832:\tlearn: 0.2560082\ttotal: 29.4s\tremaining: 5.9s\n",
      "833:\tlearn: 0.2559957\ttotal: 29.5s\tremaining: 5.87s\n",
      "834:\tlearn: 0.2559789\ttotal: 29.5s\tremaining: 5.83s\n",
      "835:\tlearn: 0.2559671\ttotal: 29.6s\tremaining: 5.8s\n",
      "836:\tlearn: 0.2559536\ttotal: 29.6s\tremaining: 5.77s\n",
      "837:\tlearn: 0.2559396\ttotal: 29.7s\tremaining: 5.74s\n",
      "838:\tlearn: 0.2559286\ttotal: 29.7s\tremaining: 5.7s\n",
      "839:\tlearn: 0.2559179\ttotal: 29.8s\tremaining: 5.67s\n",
      "840:\tlearn: 0.2559013\ttotal: 29.8s\tremaining: 5.64s\n",
      "841:\tlearn: 0.2558875\ttotal: 29.9s\tremaining: 5.6s\n",
      "842:\tlearn: 0.2558609\ttotal: 29.9s\tremaining: 5.57s\n",
      "843:\tlearn: 0.2558371\ttotal: 30s\tremaining: 5.54s\n",
      "844:\tlearn: 0.2557982\ttotal: 30s\tremaining: 5.5s\n",
      "845:\tlearn: 0.2557866\ttotal: 30.1s\tremaining: 5.47s\n",
      "846:\tlearn: 0.2557751\ttotal: 30.1s\tremaining: 5.44s\n",
      "847:\tlearn: 0.2557661\ttotal: 30.2s\tremaining: 5.41s\n",
      "848:\tlearn: 0.2557428\ttotal: 30.2s\tremaining: 5.37s\n",
      "849:\tlearn: 0.2557305\ttotal: 30.3s\tremaining: 5.34s\n",
      "850:\tlearn: 0.2557095\ttotal: 30.3s\tremaining: 5.3s\n",
      "851:\tlearn: 0.2556792\ttotal: 30.3s\tremaining: 5.27s\n",
      "852:\tlearn: 0.2556665\ttotal: 30.4s\tremaining: 5.23s\n",
      "853:\tlearn: 0.2556430\ttotal: 30.4s\tremaining: 5.2s\n",
      "854:\tlearn: 0.2556316\ttotal: 30.4s\tremaining: 5.16s\n",
      "855:\tlearn: 0.2556174\ttotal: 30.5s\tremaining: 5.12s\n",
      "856:\tlearn: 0.2556027\ttotal: 30.5s\tremaining: 5.09s\n",
      "857:\tlearn: 0.2555887\ttotal: 30.5s\tremaining: 5.05s\n",
      "858:\tlearn: 0.2555781\ttotal: 30.6s\tremaining: 5.02s\n",
      "859:\tlearn: 0.2555284\ttotal: 30.6s\tremaining: 4.98s\n",
      "860:\tlearn: 0.2555164\ttotal: 30.6s\tremaining: 4.94s\n",
      "861:\tlearn: 0.2555000\ttotal: 30.7s\tremaining: 4.91s\n",
      "862:\tlearn: 0.2554886\ttotal: 30.7s\tremaining: 4.87s\n",
      "863:\tlearn: 0.2554800\ttotal: 30.7s\tremaining: 4.83s\n",
      "864:\tlearn: 0.2554667\ttotal: 30.8s\tremaining: 4.8s\n",
      "865:\tlearn: 0.2554572\ttotal: 30.8s\tremaining: 4.76s\n",
      "866:\tlearn: 0.2554296\ttotal: 30.8s\tremaining: 4.73s\n",
      "867:\tlearn: 0.2554098\ttotal: 30.9s\tremaining: 4.69s\n",
      "868:\tlearn: 0.2553981\ttotal: 30.9s\tremaining: 4.66s\n",
      "869:\tlearn: 0.2553857\ttotal: 30.9s\tremaining: 4.62s\n",
      "870:\tlearn: 0.2553563\ttotal: 31s\tremaining: 4.59s\n",
      "871:\tlearn: 0.2553441\ttotal: 31s\tremaining: 4.55s\n",
      "872:\tlearn: 0.2553310\ttotal: 31s\tremaining: 4.51s\n",
      "873:\tlearn: 0.2553176\ttotal: 31s\tremaining: 4.47s\n",
      "874:\tlearn: 0.2553066\ttotal: 31.1s\tremaining: 4.44s\n",
      "875:\tlearn: 0.2552912\ttotal: 31.1s\tremaining: 4.4s\n",
      "876:\tlearn: 0.2552788\ttotal: 31.1s\tremaining: 4.37s\n",
      "877:\tlearn: 0.2552586\ttotal: 31.2s\tremaining: 4.33s\n",
      "878:\tlearn: 0.2552474\ttotal: 31.2s\tremaining: 4.29s\n",
      "879:\tlearn: 0.2552269\ttotal: 31.2s\tremaining: 4.26s\n",
      "880:\tlearn: 0.2552197\ttotal: 31.2s\tremaining: 4.22s\n",
      "881:\tlearn: 0.2552011\ttotal: 31.3s\tremaining: 4.18s\n",
      "882:\tlearn: 0.2551891\ttotal: 31.3s\tremaining: 4.15s\n",
      "883:\tlearn: 0.2551775\ttotal: 31.3s\tremaining: 4.11s\n",
      "884:\tlearn: 0.2551669\ttotal: 31.4s\tremaining: 4.07s\n",
      "885:\tlearn: 0.2551526\ttotal: 31.4s\tremaining: 4.04s\n",
      "886:\tlearn: 0.2551423\ttotal: 31.4s\tremaining: 4s\n",
      "887:\tlearn: 0.2551327\ttotal: 31.4s\tremaining: 3.97s\n",
      "888:\tlearn: 0.2551195\ttotal: 31.5s\tremaining: 3.93s\n",
      "889:\tlearn: 0.2551091\ttotal: 31.5s\tremaining: 3.89s\n",
      "890:\tlearn: 0.2550962\ttotal: 31.5s\tremaining: 3.86s\n",
      "891:\tlearn: 0.2550804\ttotal: 31.6s\tremaining: 3.82s\n",
      "892:\tlearn: 0.2550697\ttotal: 31.6s\tremaining: 3.78s\n",
      "893:\tlearn: 0.2550574\ttotal: 31.6s\tremaining: 3.75s\n",
      "894:\tlearn: 0.2550463\ttotal: 31.6s\tremaining: 3.71s\n",
      "895:\tlearn: 0.2550385\ttotal: 31.7s\tremaining: 3.67s\n",
      "896:\tlearn: 0.2550291\ttotal: 31.7s\tremaining: 3.64s\n",
      "897:\tlearn: 0.2549981\ttotal: 31.7s\tremaining: 3.6s\n",
      "898:\tlearn: 0.2549854\ttotal: 31.7s\tremaining: 3.56s\n",
      "899:\tlearn: 0.2549725\ttotal: 31.8s\tremaining: 3.53s\n",
      "900:\tlearn: 0.2549615\ttotal: 31.8s\tremaining: 3.49s\n",
      "901:\tlearn: 0.2549396\ttotal: 31.8s\tremaining: 3.46s\n",
      "902:\tlearn: 0.2549271\ttotal: 31.9s\tremaining: 3.42s\n",
      "903:\tlearn: 0.2549163\ttotal: 31.9s\tremaining: 3.38s\n",
      "904:\tlearn: 0.2549065\ttotal: 31.9s\tremaining: 3.35s\n",
      "905:\tlearn: 0.2548962\ttotal: 31.9s\tremaining: 3.31s\n",
      "906:\tlearn: 0.2548839\ttotal: 31.9s\tremaining: 3.28s\n",
      "907:\tlearn: 0.2548725\ttotal: 32s\tremaining: 3.24s\n",
      "908:\tlearn: 0.2548628\ttotal: 32s\tremaining: 3.2s\n",
      "909:\tlearn: 0.2548503\ttotal: 32s\tremaining: 3.17s\n",
      "910:\tlearn: 0.2548414\ttotal: 32.1s\tremaining: 3.13s\n",
      "911:\tlearn: 0.2548335\ttotal: 32.1s\tremaining: 3.1s\n",
      "912:\tlearn: 0.2548115\ttotal: 32.1s\tremaining: 3.06s\n",
      "913:\tlearn: 0.2547992\ttotal: 32.1s\tremaining: 3.02s\n",
      "914:\tlearn: 0.2547812\ttotal: 32.2s\tremaining: 2.99s\n",
      "915:\tlearn: 0.2547720\ttotal: 32.2s\tremaining: 2.95s\n",
      "916:\tlearn: 0.2547632\ttotal: 32.2s\tremaining: 2.92s\n",
      "917:\tlearn: 0.2547520\ttotal: 32.2s\tremaining: 2.88s\n",
      "918:\tlearn: 0.2547306\ttotal: 32.3s\tremaining: 2.84s\n",
      "919:\tlearn: 0.2547233\ttotal: 32.3s\tremaining: 2.81s\n",
      "920:\tlearn: 0.2547117\ttotal: 32.3s\tremaining: 2.77s\n",
      "921:\tlearn: 0.2547018\ttotal: 32.3s\tremaining: 2.74s\n",
      "922:\tlearn: 0.2546909\ttotal: 32.4s\tremaining: 2.7s\n",
      "923:\tlearn: 0.2546617\ttotal: 32.4s\tremaining: 2.66s\n",
      "924:\tlearn: 0.2546502\ttotal: 32.4s\tremaining: 2.63s\n",
      "925:\tlearn: 0.2546407\ttotal: 32.4s\tremaining: 2.59s\n",
      "926:\tlearn: 0.2546290\ttotal: 32.5s\tremaining: 2.56s\n",
      "927:\tlearn: 0.2545959\ttotal: 32.5s\tremaining: 2.52s\n",
      "928:\tlearn: 0.2545841\ttotal: 32.5s\tremaining: 2.48s\n",
      "929:\tlearn: 0.2545751\ttotal: 32.5s\tremaining: 2.45s\n",
      "930:\tlearn: 0.2545656\ttotal: 32.6s\tremaining: 2.41s\n",
      "931:\tlearn: 0.2545152\ttotal: 32.6s\tremaining: 2.38s\n",
      "932:\tlearn: 0.2544991\ttotal: 32.6s\tremaining: 2.34s\n",
      "933:\tlearn: 0.2544910\ttotal: 32.6s\tremaining: 2.31s\n",
      "934:\tlearn: 0.2544816\ttotal: 32.7s\tremaining: 2.27s\n",
      "935:\tlearn: 0.2544662\ttotal: 32.7s\tremaining: 2.23s\n",
      "936:\tlearn: 0.2544192\ttotal: 32.7s\tremaining: 2.2s\n",
      "937:\tlearn: 0.2544077\ttotal: 32.8s\tremaining: 2.17s\n",
      "938:\tlearn: 0.2543842\ttotal: 32.8s\tremaining: 2.13s\n",
      "939:\tlearn: 0.2543627\ttotal: 32.8s\tremaining: 2.09s\n",
      "940:\tlearn: 0.2543435\ttotal: 32.8s\tremaining: 2.06s\n",
      "941:\tlearn: 0.2543321\ttotal: 32.9s\tremaining: 2.02s\n",
      "942:\tlearn: 0.2543166\ttotal: 32.9s\tremaining: 1.99s\n",
      "943:\tlearn: 0.2543063\ttotal: 33s\tremaining: 1.96s\n",
      "944:\tlearn: 0.2542849\ttotal: 33s\tremaining: 1.92s\n",
      "945:\tlearn: 0.2542747\ttotal: 33.1s\tremaining: 1.89s\n",
      "946:\tlearn: 0.2542598\ttotal: 33.1s\tremaining: 1.85s\n",
      "947:\tlearn: 0.2542485\ttotal: 33.2s\tremaining: 1.82s\n",
      "948:\tlearn: 0.2542384\ttotal: 33.2s\tremaining: 1.78s\n",
      "949:\tlearn: 0.2542176\ttotal: 33.3s\tremaining: 1.75s\n",
      "950:\tlearn: 0.2542102\ttotal: 33.3s\tremaining: 1.72s\n",
      "951:\tlearn: 0.2542020\ttotal: 33.4s\tremaining: 1.68s\n",
      "952:\tlearn: 0.2541798\ttotal: 33.4s\tremaining: 1.65s\n",
      "953:\tlearn: 0.2541703\ttotal: 33.5s\tremaining: 1.61s\n",
      "954:\tlearn: 0.2541512\ttotal: 33.5s\tremaining: 1.58s\n",
      "955:\tlearn: 0.2541371\ttotal: 33.5s\tremaining: 1.54s\n",
      "956:\tlearn: 0.2541276\ttotal: 33.6s\tremaining: 1.51s\n",
      "957:\tlearn: 0.2541152\ttotal: 33.7s\tremaining: 1.48s\n",
      "958:\tlearn: 0.2541001\ttotal: 33.7s\tremaining: 1.44s\n",
      "959:\tlearn: 0.2540892\ttotal: 33.7s\tremaining: 1.41s\n",
      "960:\tlearn: 0.2540791\ttotal: 33.8s\tremaining: 1.37s\n",
      "961:\tlearn: 0.2540642\ttotal: 33.9s\tremaining: 1.34s\n",
      "962:\tlearn: 0.2540543\ttotal: 33.9s\tremaining: 1.3s\n",
      "963:\tlearn: 0.2540445\ttotal: 34s\tremaining: 1.27s\n",
      "964:\tlearn: 0.2540359\ttotal: 34s\tremaining: 1.23s\n",
      "965:\tlearn: 0.2540261\ttotal: 34.1s\tremaining: 1.2s\n",
      "966:\tlearn: 0.2540101\ttotal: 34.1s\tremaining: 1.16s\n",
      "967:\tlearn: 0.2539985\ttotal: 34.2s\tremaining: 1.13s\n",
      "968:\tlearn: 0.2539870\ttotal: 34.3s\tremaining: 1.1s\n",
      "969:\tlearn: 0.2539620\ttotal: 34.3s\tremaining: 1.06s\n",
      "970:\tlearn: 0.2539441\ttotal: 34.4s\tremaining: 1.03s\n",
      "971:\tlearn: 0.2539303\ttotal: 34.4s\tremaining: 992ms\n",
      "972:\tlearn: 0.2539205\ttotal: 34.5s\tremaining: 958ms\n",
      "973:\tlearn: 0.2538967\ttotal: 34.6s\tremaining: 923ms\n",
      "974:\tlearn: 0.2538814\ttotal: 34.7s\tremaining: 889ms\n",
      "975:\tlearn: 0.2538619\ttotal: 34.7s\tremaining: 853ms\n",
      "976:\tlearn: 0.2538516\ttotal: 34.7s\tremaining: 818ms\n",
      "977:\tlearn: 0.2538219\ttotal: 34.8s\tremaining: 783ms\n",
      "978:\tlearn: 0.2538134\ttotal: 34.8s\tremaining: 747ms\n",
      "979:\tlearn: 0.2538048\ttotal: 34.9s\tremaining: 712ms\n",
      "980:\tlearn: 0.2537969\ttotal: 34.9s\tremaining: 676ms\n",
      "981:\tlearn: 0.2537890\ttotal: 34.9s\tremaining: 640ms\n",
      "982:\tlearn: 0.2537679\ttotal: 35s\tremaining: 605ms\n",
      "983:\tlearn: 0.2537585\ttotal: 35s\tremaining: 569ms\n",
      "984:\tlearn: 0.2537190\ttotal: 35s\tremaining: 534ms\n",
      "985:\tlearn: 0.2537105\ttotal: 35.1s\tremaining: 498ms\n",
      "986:\tlearn: 0.2536987\ttotal: 35.1s\tremaining: 462ms\n",
      "987:\tlearn: 0.2536808\ttotal: 35.1s\tremaining: 427ms\n",
      "988:\tlearn: 0.2536694\ttotal: 35.2s\tremaining: 391ms\n",
      "989:\tlearn: 0.2536478\ttotal: 35.2s\tremaining: 356ms\n",
      "990:\tlearn: 0.2536349\ttotal: 35.2s\tremaining: 320ms\n",
      "991:\tlearn: 0.2536271\ttotal: 35.3s\tremaining: 285ms\n",
      "992:\tlearn: 0.2536186\ttotal: 35.3s\tremaining: 249ms\n",
      "993:\tlearn: 0.2536051\ttotal: 35.4s\tremaining: 213ms\n",
      "994:\tlearn: 0.2535941\ttotal: 35.4s\tremaining: 178ms\n",
      "995:\tlearn: 0.2535830\ttotal: 35.4s\tremaining: 142ms\n",
      "996:\tlearn: 0.2535739\ttotal: 35.5s\tremaining: 107ms\n",
      "997:\tlearn: 0.2535689\ttotal: 35.5s\tremaining: 71.1ms\n",
      "998:\tlearn: 0.2535579\ttotal: 35.5s\tremaining: 35.6ms\n",
      "999:\tlearn: 0.2535514\ttotal: 35.5s\tremaining: 0us\n",
      "Confusion Matrix: \n",
      " [[206381   2634]\n",
      " [ 24275  13708]]\n",
      "Accuracy:  0.8910557980226561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94    209015\n",
      "           1       0.84      0.36      0.50     37983\n",
      "\n",
      "    accuracy                           0.89    246998\n",
      "   macro avg       0.87      0.67      0.72    246998\n",
      "weighted avg       0.89      0.89      0.87    246998\n",
      "\n",
      "AUC: 0.8930850670475566\n"
     ]
    }
   ],
   "source": [
    "cat_new = CatBoostClassifier(random_state=0, depth = 5, learning_rate = 0.01)\n",
    "cat_pred, cat_prob, cat_acc, cat_precision, cat_recall, cat_f1, cat_auc = fit_evaluate(cat_new,X_train_pre,y_train,X_test_pre,y_test)"
   ]
  },
  {
   "source": [
    "## Sampling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataframe to store results\n",
    "evaluation = pd.DataFrame(columns=['Accuracy', 'ROC', 'Precision', 'Recall', 'F1-score'],index=['lr','knn','rf','xgb','mnb','gnb','lgbm','cat'])\n",
    "models=['lr','knn','rf','xgb','mnb','gnb','lgbm','cat']\n",
    "for model in models:\n",
    "     evaluation.loc[model] = [globals()[model + \"_acc\"], globals()[model + \"_auc\"], globals()[model + \"_precision\"],globals()[model + \"_recall\"],globals()[model + \"_f1\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Accuracy       ROC Precision    Recall  F1-score\n",
       "lr     0.87772  0.771206  0.809516  0.267857  0.402524\n",
       "knn   0.873177  0.715423  0.700421  0.306295  0.426208\n",
       "rf    0.883874  0.843914   0.82682  0.309718  0.450633\n",
       "xgb   0.892785    0.8969  0.799677  0.403997  0.536801\n",
       "mnb   0.871728  0.688521  0.630176  0.401469  0.490471\n",
       "gnb   0.870703  0.770825  0.900942  0.178869   0.29848\n",
       "lgbm  0.891481  0.893141  0.840927  0.362978   0.50708\n",
       "cat   0.891056  0.893085   0.83882  0.360898  0.504666"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>ROC</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1-score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lr</th>\n      <td>0.87772</td>\n      <td>0.771206</td>\n      <td>0.809516</td>\n      <td>0.267857</td>\n      <td>0.402524</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>0.873177</td>\n      <td>0.715423</td>\n      <td>0.700421</td>\n      <td>0.306295</td>\n      <td>0.426208</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>0.883874</td>\n      <td>0.843914</td>\n      <td>0.82682</td>\n      <td>0.309718</td>\n      <td>0.450633</td>\n    </tr>\n    <tr>\n      <th>xgb</th>\n      <td>0.892785</td>\n      <td>0.8969</td>\n      <td>0.799677</td>\n      <td>0.403997</td>\n      <td>0.536801</td>\n    </tr>\n    <tr>\n      <th>mnb</th>\n      <td>0.871728</td>\n      <td>0.688521</td>\n      <td>0.630176</td>\n      <td>0.401469</td>\n      <td>0.490471</td>\n    </tr>\n    <tr>\n      <th>gnb</th>\n      <td>0.870703</td>\n      <td>0.770825</td>\n      <td>0.900942</td>\n      <td>0.178869</td>\n      <td>0.29848</td>\n    </tr>\n    <tr>\n      <th>lgbm</th>\n      <td>0.891481</td>\n      <td>0.893141</td>\n      <td>0.840927</td>\n      <td>0.362978</td>\n      <td>0.50708</td>\n    </tr>\n    <tr>\n      <th>cat</th>\n      <td>0.891056</td>\n      <td>0.893085</td>\n      <td>0.83882</td>\n      <td>0.360898</td>\n      <td>0.504666</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd09eed60dbd6a125bb254a1809294fda76bfa602708d8a341367b22e51006fb8cb",
   "display_name": "Python 3.8.8 64-bit ('whale': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "9eed60dbd6a125bb254a1809294fda76bfa602708d8a341367b22e51006fb8cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}